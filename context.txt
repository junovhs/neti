<file path=".gitignore">
# Rust build artifacts
/target/
/docs/
/Cargo.lock

# Logs and temp files
*.log
*.tmp
*.bak

# Generated AI pack and test fixtures
ai-pack/
tests/tmp/
tmp/
*.manifest.json

# Editor/OS files
.DS_Store
Thumbs.db
.idea/
.vscode/
*.swp
*.swo

# Git / OS cruft
*~
*.orig

# Node / frontend extras
node_modules/
dist/
build/
coverage/
.env

# Python extras
__pycache__/
.venv/
venv/

# Repomix or AI output
*.xml
*.jsonl

# Ignore everything inside /target/release except binaries we care about
!/target/release/saccade.exe
!/target/release/gauntlet.exe</file>

<file path="Cargo.toml">
[package]
name = "warden"
version = "0.4.0"
edition = "2021"

[lib]
name = "warden_core"
path = "src/lib.rs"

[[bin]]
name = "warden"
path = "src/bin/warden.rs"

[[bin]]
name = "knit"
path = "src/bin/knit.rs"

[dependencies]
anyhow = "1.0"
thiserror = "1.0"
regex = "1.10"
walkdir = "2.5"
clap = { version = "4.5", features = ["derive"] }
ignore = "0.4"
colored = "2.1"
rayon = "1.10"
once_cell = "1.19"
serde = { version = "1.0", features = ["derive"] }
toml = "0.8"
arboard = "3.4"

# THE BRAINS
tiktoken-rs = "0.5"

# UI / TUI
ratatui = "0.29"
crossterm = "0.28"

# Structural Parsing
tree-sitter = "0.20"
tree-sitter-rust = "0.20"
tree-sitter-python = "0.20"
tree-sitter-typescript = "0.20"
tree-sitter-javascript = "0.20"
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Spencer Nunamaker

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="README.md">
# üõ°Ô∏è Warden Protocol

**Architecture Governance based on NASA's "Power of 10".**

> *"The rules are like the seat belts in a car: Initially, using them is perhaps a little uncomfortable, but after a while, it becomes second nature, and not using them is unimaginable."* ‚Äî Gerard J. Holzmann

Warden is a structural linter and "Architectural MRI" designed to enforce **High-Integrity Coding Standards**. It is a modern, multi-language adaptation of the **[NASA/JPL "Power of 10" Rules](https://web.eecs.umich.edu/~imarkov/10rules.pdf)** (Holzmann, 2006) for safety-critical software.

While originally designed for C, Warden adapts these principles for Rust, TypeScript, and Python to solve the "Context Drift" and "Complexity Creep" problems common in modern development (and AI-assisted workflows).

**v0.4.0 Update:** Now featuring a TUI Dashboard, Cyclomatic Complexity analysis, and a unified "Super Command" system.

---

## üì∏ The Architectural MRI (TUI)

Warden includes a hardware-accelerated TUI to visualize codebase health in real-time.

```bash
warden --ui
```

<p align="center">
  <img src="assets/screenshot.png" alt="Warden TUI Dashboard" width="700">
</p>

It features:
*   **Heatmap List:** Instantly spot complex files (Yellow) or violating files (Red).
*   **Mini-Gauges:** Inline visualization of file size vs. token budget.
*   **Compliance Stress:** A metric derived from the density of violations in a file.


---

## ‚ö° The 3 Laws (Adapted from Holzmann)

Warden uses **Tree-sitter** to parse the AST and enforce:

### 1. The Law of Atomicity (Holzmann Rule 4)
*   **Rule:** No file may exceed **2000 Tokens** (approx. 60-100 logical statements).
*   **Original Rationale:** *"Each function should be a logical unit... verifiable as a unit."*
*   **Modern Benefit:** Forces modularity and ensures AI context windows remain high-signal.

### 2. The Law of Complexity (Holzmann Rules 1 & 2)
*   **Cyclomatic Complexity:** Max **10**. (Simple control flow).
*   **Nesting Depth:** Max **4**. (No "Arrow Code").
*   **Arity:** Max **5** arguments. (Enforces Data Structures).
*   **Original Rationale:** *"Simpler control flow translates into stronger capabilities for analysis."*

### 3. The Law of Paranoia (Holzmann Rules 5, 7, & 10)
*   **Rule:** Logic bodies must contain explicit error handling (`Result`, `try/catch`).
*   **Rule:** No `unwrap()` allowed. Zero Warnings tolerated.
*   **Original Rationale:** *"The odds of intercepting defects increase significantly with increasing assertion density."*

---

## üöÄ The "God Command"

Warden acts as a pipeline runner to enforce **Rule 10** (Pedantic Compilation).

**One command to rule them all:**
```bash
warden check
```

*Configured in `warden.toml`:*
```toml
[commands]
# Runs Clippy Pedantic -> If Pass -> Runs Warden Scan
check = "cargo clippy --all-targets -- -D warnings -D clippy::pedantic"
```

---

## üì¶ Installation

```bash
cargo install --path . --force
```

## üõ†Ô∏è Configuration

Run `warden --init` to generate a `warden.toml` with NASA-standard defaults.

```toml
[rules]
max_file_tokens = 2000
max_cyclomatic_complexity = 10
max_nesting_depth = 4
```

## ü§ñ The AI System Prompt

To enforce these rules with LLMs/Agents:

```text
ROLE: High-Integrity Systems Architect (Standard: JPL/Holzmann).
CONTEXT: You are coding inside a strict environment enforced by 'Warden'.

THE 3 LAWS (Non-Negotiable):
1. LAW OF ATOMICITY: Files < 200 Lines. Split VIEW from LOGIC.
2. LAW OF COMPLEXITY: Nesting < 4. Args < 5. Complexity < 10.
3. LAW OF PARANOIA: Validate inputs at Line 1. No unwrap(). Return Result<>.

OPERATIONAL PROTOCOL:
1. Scan: Read context.
2. Generate: Output WHOLE FILES.
3. Verify: "Will Warden reject this?"
```

**License:** MIT
</file>

<file path="src/analysis.rs">
// src/analysis.rs
use crate::checks::{self, CheckContext};
use crate::config::RuleConfig;
use crate::types::Violation;
use anyhow::Result;
use tree_sitter::{Language, Parser, Query};

pub struct Analyzer {
    rust_naming: Query,
    rust_safety: Query,
    rust_complexity: Query,
    rust_banned: Query,
    js_naming: Query,
    js_safety: Query,
    js_complexity: Query,
    py_naming: Query,
    py_safety: Query,
    py_complexity: Query,
}

impl Default for Analyzer {
    fn default() -> Self {
        Self::new()
    }
}

impl Analyzer {
    #[must_use]
    pub fn new() -> Self {
        Self {
            rust_naming: q(
                tree_sitter_rust::language(),
                "(function_item name: (identifier) @name)",
            ),
            rust_safety: q(tree_sitter_rust::language(), r"(match_expression) @safe"),
            rust_complexity: q(
                tree_sitter_rust::language(),
                r#"
                (if_expression) @branch
                (match_arm) @branch
                (while_expression) @branch
                (for_expression) @branch
                (binary_expression operator: ["&&" "||"]) @branch
            "#,
            ),
            rust_banned: q(
                tree_sitter_rust::language(),
                r#"
                (call_expression function: (field_expression field: (field_identifier) @m (#eq? @m "unwrap"))) @banned
            "#,
            ),
            js_naming: q(
                tree_sitter_typescript::language_typescript(),
                r"
                (function_declaration name: (identifier) @name)
                (method_definition name: (property_identifier) @name)
                (variable_declarator name: (identifier) @name value: [(arrow_function) (function_expression)])
            ",
            ),
            js_safety: q(
                tree_sitter_typescript::language_typescript(),
                r"(try_statement) @safe",
            ),
            js_complexity: q(
                tree_sitter_typescript::language_typescript(),
                r#"
                (if_statement) @branch
                (for_statement) @branch
                (for_in_statement) @branch
                (while_statement) @branch
                (do_statement) @branch
                (switch_case) @branch
                (catch_clause) @branch
                (ternary_expression) @branch
                (binary_expression operator: ["&&" "||" "??"]) @branch
            "#,
            ),
            py_naming: q(
                tree_sitter_python::language(),
                "(function_definition name: (identifier) @name)",
            ),
            py_safety: q(tree_sitter_python::language(), r"(try_statement) @safe"),
            py_complexity: q(
                tree_sitter_python::language(),
                r"
                (if_statement) @branch
                (for_statement) @branch
                (while_statement) @branch
                (except_clause) @branch
                (boolean_operator) @branch
            ",
            ),
        }
    }

    #[must_use]
    pub fn analyze(
        &self,
        lang: &str,
        filename: &str,
        content: &str,
        config: &RuleConfig,
    ) -> Vec<Violation> {
        let Some(queries) = self.select_language(lang) else {
            return vec![];
        };
        Self::run_analysis(queries, filename, content, config)
    }

    fn select_language(
        &self,
        lang: &str,
    ) -> Option<(Language, &Query, &Query, &Query, Option<&Query>)> {
        if lang == "rs" {
            return Some(self.queries_rust());
        }
        if matches!(lang, "js" | "jsx" | "ts" | "tsx") {
            return Some(self.queries_js());
        }
        if lang == "py" {
            return Some(self.queries_python());
        }
        None
    }

    fn queries_rust(&self) -> (Language, &Query, &Query, &Query, Option<&Query>) {
        (
            tree_sitter_rust::language(),
            &self.rust_naming,
            &self.rust_safety,
            &self.rust_complexity,
            Some(&self.rust_banned),
        )
    }

    fn queries_js(&self) -> (Language, &Query, &Query, &Query, Option<&Query>) {
        (
            tree_sitter_typescript::language_typescript(),
            &self.js_naming,
            &self.js_safety,
            &self.js_complexity,
            None,
        )
    }

    fn queries_python(&self) -> (Language, &Query, &Query, &Query, Option<&Query>) {
        (
            tree_sitter_python::language(),
            &self.py_naming,
            &self.py_safety,
            &self.py_complexity,
            None,
        )
    }

    fn run_analysis(
        (language, naming, safety, complexity, banned): (
            Language,
            &Query,
            &Query,
            &Query,
            Option<&Query>,
        ),
        filename: &str,
        content: &str,
        config: &RuleConfig,
    ) -> Vec<Violation> {
        let mut parser_instance = Parser::new();
        let Ok(parser) = parser_instance.get_init(language) else {
            return vec![];
        };

        let Some(tree) = parser.parse(content, None) else {
            return vec![];
        };

        let mut violations = Vec::new();
        let ctx = CheckContext {
            root: tree.root_node(),
            source: content,
            filename,
            config,
        };

        checks::check_naming(&ctx, naming, &mut violations);
        checks::check_safety(&ctx, safety, &mut violations);
        checks::check_metrics(&ctx, complexity, &mut violations);

        if let Some(bq) = banned {
            let _ = checks::check_banned(&ctx, bq, &mut violations);
        }

        violations
    }
}

trait ParserInit {
    fn get_init(&mut self, lang: Language) -> Result<&mut Self>;
}

impl ParserInit for Parser {
    fn get_init(&mut self, lang: Language) -> Result<&mut Self> {
        self.set_language(lang)?;
        Ok(self)
    }
}

fn q(lang: Language, pattern: &str) -> Query {
    Query::new(lang, pattern).expect("Invalid Query")
}
</file>

<file path="src/bin/knit.rs">
// src/bin/knit.rs
use anyhow::Result;
use clap::{Parser, ValueEnum};
use colored::Colorize;
use std::fmt::Write;
use std::fs;
use std::path::PathBuf;

use warden_core::config::{Config, GitMode};
use warden_core::enumerate::FileEnumerator;
use warden_core::filter::FileFilter;
use warden_core::heuristics::HeuristicFilter;
use warden_core::prompt::PromptGenerator;
use warden_core::tokens::Tokenizer;

#[derive(Debug, Clone, ValueEnum)]
enum OutputFormat {
    Text,
    Xml,
}

#[derive(Parser)]
#[command(name = "knit")]
#[command(about = "Stitches atomic files into a single context file.")]
#[allow(clippy::struct_excessive_bools)]
struct Cli {
    #[arg(long, short)]
    stdout: bool,
    #[arg(long, short)]
    verbose: bool,
    #[arg(long)]
    git_only: bool,
    #[arg(long)]
    no_git: bool,
    #[arg(long)]
    code_only: bool,
    #[arg(long, short)]
    prompt: bool,
    #[arg(long, value_enum, default_value_t = OutputFormat::Text)]
    format: OutputFormat,
}

fn main() -> Result<()> {
    let cli = Cli::parse();
    let config = setup_config(&cli)?;

    if !cli.stdout {
        println!("üß∂ Knitting repository...");
    }

    let files = discover_files(&config, cli.verbose)?;
    let content = generate_content(&files, &cli, &config)?;
    let token_count = Tokenizer::count(&content);

    output_result(&content, token_count, cli.stdout)
}

fn setup_config(cli: &Cli) -> Result<Config> {
    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;
    config.git_mode = if cli.git_only {
        GitMode::Yes
    } else if cli.no_git {
        GitMode::No
    } else {
        GitMode::Auto
    };
    config.load_local_config();
    config.validate()?;
    Ok(config)
}

fn discover_files(config: &Config, verbose: bool) -> Result<Vec<PathBuf>> {
    let raw = FileEnumerator::new(config.clone()).enumerate()?;
    let h_files = HeuristicFilter::new().filter(raw);
    let t_files = FileFilter::new(config)?.filter(h_files);

    if verbose {
        eprintln!("üì¶ Packing {} files...", t_files.len());
    }
    Ok(t_files)
}

fn generate_content(files: &[PathBuf], cli: &Cli, config: &Config) -> Result<String> {
    let mut ctx = String::with_capacity(100_000);

    if cli.prompt {
        write_header(&mut ctx, config)?;
    }

    write_body(files, &mut ctx, &cli.format)?;

    if cli.prompt {
        write_footer(&mut ctx, config)?;
    }

    Ok(ctx)
}

fn write_body(files: &[PathBuf], ctx: &mut String, format: &OutputFormat) -> Result<()> {
    match format {
        OutputFormat::Text => pack_text(files, ctx),
        OutputFormat::Xml => pack_xml(files, ctx),
    }
}

fn write_header(ctx: &mut String, config: &Config) -> Result<()> {
    let gen = PromptGenerator::new(config.rules.clone());
    writeln!(ctx, "{}", gen.wrap_header()?)?;
    writeln!(ctx, "\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nBEGIN CODEBASE\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")?;
    Ok(())
}

fn write_footer(ctx: &mut String, config: &Config) -> Result<()> {
    let gen = PromptGenerator::new(config.rules.clone());
    writeln!(ctx, "\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nEND CODEBASE\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n")?;
    writeln!(ctx, "{}", gen.generate_reminder()?)?;
    Ok(())
}

fn output_result(content: &str, tokens: usize, stdout: bool) -> Result<()> {
    let info = format!(
        "\nüìä Context Size: {} tokens",
        tokens.to_string().yellow().bold()
    );

    if stdout {
        print!("{content}");
        eprintln!("{info}");
    } else {
        fs::write("context.txt", content)?;
        println!("‚úÖ Generated 'context.txt'");
        println!("{info}");
    }
    Ok(())
}

fn pack_text(files: &[PathBuf], out: &mut String) -> Result<()> {
    for path in files {
        let p_str = path.to_string_lossy().replace('\\', "/");
        writeln!(out, "<file path=\"{p_str}\">")?;
        match fs::read_to_string(path) {
            Ok(c) => out.push_str(&c),
            Err(e) => writeln!(out, "<ERROR READING FILE: {e}>")?,
        }
        writeln!(out, "</file>\n")?;
    }
    Ok(())
}

fn pack_xml(files: &[PathBuf], out: &mut String) -> Result<()> {
    writeln!(out, "<documents>")?;
    for path in files {
        let p_str = path.to_string_lossy().replace('\\', "/");
        writeln!(out, "  <document path=\"{p_str}\"><![CDATA[")?;
        match fs::read_to_string(path) {
            Ok(c) => out.push_str(&c.replace("]]>", "]]]]><![CDATA[>")),
            Err(e) => writeln!(out, "ERROR READING FILE: {e}")?,
        }
        writeln!(out, "]]></document>")?;
    }
    writeln!(out, "</documents>")?;
    Ok(())
}
</file>

<file path="src/bin/warden.rs">
// src/bin/warden.rs
use anyhow::Result;
use clap::{Parser, Subcommand};
use colored::Colorize;
use crossterm::{
    event::{DisableMouseCapture, EnableMouseCapture},
    execute,
    terminal::{disable_raw_mode, enable_raw_mode, EnterAlternateScreen, LeaveAlternateScreen},
};
use std::fs;
use std::io;
use std::process::{self, Command};

use warden_core::apply;
use warden_core::clipboard;
use warden_core::config::{Config, GitMode};
use warden_core::enumerate::FileEnumerator;
use warden_core::filter::FileFilter;
use warden_core::heuristics::HeuristicFilter;
use warden_core::prompt::PromptGenerator;
use warden_core::reporting;
use warden_core::rules::RuleEngine;
use warden_core::tui::state::App;
use warden_core::types::ScanReport;

#[derive(Subcommand)]
enum Commands {
    Prompt {
        #[arg(long, short)]
        copy: bool,
        #[arg(long, short)]
        short: bool,
    },
    Run {
        name: String,
    },
    Apply {
        #[arg(long)]
        dry_run: bool,
    },
    Undo,
}

#[derive(Parser)]
#[command(name = "warden")]
#[command(about = "Structural linter for Code With Intent")]
#[allow(clippy::struct_excessive_bools)]
struct Cli {
    #[arg(long, short)]
    verbose: bool,
    #[arg(long)]
    git_only: bool,
    #[arg(long)]
    no_git: bool,
    #[arg(long)]
    code_only: bool,
    #[arg(long)]
    init: bool,
    #[arg(long)]
    ui: bool,

    #[command(subcommand)]
    command: Option<Commands>,

    #[arg(index = 1)]
    legacy_command: Option<String>,
}

fn main() -> Result<()> {
    let cli = Cli::parse();

    if cli.init {
        return init_config();
    }

    let config = load_config(&cli)?;

    if let Some(cmd) = &cli.command {
        return exec_subcommand(cmd, &config);
    }

    if let Some(cmd_name) = &cli.legacy_command {
        run_alias(&config, cmd_name);
    }

    run_scan(&config, cli.ui)
}

fn init_config() -> Result<()> {
    if std::path::Path::new("warden.toml").exists() {
        println!("{}", "‚ö†Ô∏è warden.toml already exists.".yellow());
    } else {
        let default_toml = r#"# warden.toml
[rules]
max_file_tokens = 2000
max_cyclomatic_complexity = 10
max_nesting_depth = 4
max_function_args = 5
max_function_words = 3
ignore_naming_on = ["tests", "spec"]

[commands]
check = "cargo clippy --all-targets -- -D warnings -D clippy::pedantic"
"#;
        fs::write("warden.toml", default_toml)?;
        println!("{}", "‚úÖ Created warden.toml".green());
    }
    Ok(())
}

fn load_config(cli: &Cli) -> Result<Config> {
    let mut config = Config::new();
    config.verbose = cli.verbose;
    config.code_only = cli.code_only;
    config.git_mode = if cli.git_only {
        GitMode::Yes
    } else if cli.no_git {
        GitMode::No
    } else {
        GitMode::Auto
    };
    config.load_local_config();
    config.validate()?;
    Ok(config)
}

fn exec_subcommand(cmd: &Commands, config: &Config) -> Result<()> {
    match cmd {
        Commands::Prompt { copy, short } => show_prompt(config, *copy, *short),
        Commands::Run { name } => {
            run_alias(config, name);
            Ok(())
        }
        Commands::Apply { dry_run } => run_apply(*dry_run),
        Commands::Undo => run_undo(),
    }
}

fn show_prompt(config: &Config, copy: bool, short: bool) -> Result<()> {
    let generator = PromptGenerator::new(config.rules.clone());
    let output = if short {
        generator.generate_reminder()?
    } else {
        generator.wrap_header()?
    };

    if copy {
        clipboard::copy_to_clipboard(&output)?;
        println!("{}", "‚úÖ Copied to clipboard".green());
    } else {
        println!("{output}");
    }
    Ok(())
}

fn run_alias(config: &Config, name: &str) {
    if let Some(cmd_str) = config.commands.get(name) {
        println!("üöÄ Running '{}': {}", name.cyan(), cmd_str.yellow());
        execute_command_string(cmd_str);
    } else {
        println!("‚ö†Ô∏è Unknown command: '{}'", name.yellow());
        process::exit(1);
    }
}

fn execute_command_string(cmd_str: &str) {
    let mut parts = cmd_str.split_whitespace();
    if let Some(prog) = parts.next() {
        let status = Command::new(prog)
            .args(parts)
            .status()
            .unwrap_or_else(|_| process::exit(1));

        if !status.success() {
            process::exit(status.code().unwrap_or(1));
        }
    }
}

fn run_apply(dry_run: bool) -> Result<()> {
    if dry_run {
        println!("{}", "üîç Dry run mode - no files will be written".yellow());
    }

    match apply::run_apply(dry_run) {
        Ok(outcome) => {
            apply::print_result(&outcome);
            match outcome {
                apply::types::ApplyOutcome::Success { .. } => Ok(()),
                _ => {
                    process::exit(1);
                }
            }
        }
        Err(e) => {
            println!("{}", format!("‚ùå Error: {e}").red());
            process::exit(1);
        }
    }
}

fn run_undo() -> Result<()> {
    println!("{}", "üîÑ Restoring from backup...".yellow());

    match apply::run_undo() {
        Ok(restored) => {
            println!("{}", "‚úÖ Restored files:".green());
            for file in restored {
                println!("   {} {}", "‚úì".green(), file.display());
            }
            Ok(())
        }
        Err(e) => {
            println!("{}", format!("‚ùå Error: {e}").red());
            process::exit(1);
        }
    }
}

fn run_scan(config: &Config, use_ui: bool) -> Result<()> {
    let files = discover_files(config)?;
    if files.is_empty() {
        println!("No files to scan.");
        return Ok(());
    }

    let report = RuleEngine::new(config.clone()).scan(files);

    if use_ui {
        run_tui_app(report)
    } else {
        reporting::print_report(&report)?;
        if report.total_violations > 0 {
            process::exit(1);
        }
        Ok(())
    }
}

fn discover_files(config: &Config) -> Result<Vec<std::path::PathBuf>> {
    let raw = FileEnumerator::new(config.clone()).enumerate()?;
    let heuristic = HeuristicFilter::new().filter(raw);
    let filtered = FileFilter::new(config)?.filter(heuristic);
    Ok(filtered)
}

fn run_tui_app(report: ScanReport) -> Result<()> {
    enable_raw_mode()?;
    let mut stdout = io::stdout();
    execute!(stdout, EnterAlternateScreen, EnableMouseCapture)?;
    let backend = ratatui::backend::CrosstermBackend::new(stdout);
    let mut terminal = ratatui::Terminal::new(backend)?;

    let mut app = App::new(report);
    let res = app.run(&mut terminal);

    disable_raw_mode()?;
    execute!(
        terminal.backend_mut(),
        LeaveAlternateScreen,
        DisableMouseCapture
    )?;
    terminal.show_cursor()?;

    if let Err(err) = res {
        println!("{err:?}");
    }
    Ok(())
}
</file>

<file path="src/checks.rs">
// src/checks.rs
use crate::config::RuleConfig;
use crate::metrics;
use crate::types::Violation;
use anyhow::Result;
use tree_sitter::{Node, Query, QueryCursor, TreeCursor};

pub struct CheckContext<'a> {
    pub root: Node<'a>,
    pub source: &'a str,
    pub filename: &'a str,
    pub config: &'a RuleConfig,
}

/// Checks for naming violations.
pub fn check_naming(ctx: &CheckContext, query: &Query, out: &mut Vec<Violation>) {
    let mut cursor = QueryCursor::new();
    for m in cursor.matches(query, ctx.root, ctx.source.as_bytes()) {
        let node = m.captures[0].node;
        let name = node.utf8_text(ctx.source.as_bytes()).unwrap_or("?");

        if is_ignored(ctx.filename, &ctx.config.ignore_naming_on) {
            continue;
        }

        let word_count = count_words(name);
        if word_count > ctx.config.max_function_words {
            out.push(Violation {
                row: node.start_position().row,
                message: format!(
                    "Function '{name}' has {word_count} words (Max: {}). Is it doing too much?",
                    ctx.config.max_function_words
                ),
                law: "LAW OF BLUNTNESS",
            });
        }
    }
}

fn count_words(name: &str) -> usize {
    if name.contains('_') {
        name.split('_').count()
    } else {
        let caps = name.chars().filter(|c| c.is_uppercase()).count();
        if name.chars().next().is_some_and(char::is_uppercase) {
            caps
        } else {
            caps + 1
        }
    }
}

fn is_ignored(filename: &str, patterns: &[String]) -> bool {
    patterns.iter().any(|p| filename.contains(p))
}

/// Checks for safety violations.
pub fn check_safety(ctx: &CheckContext, _safety_query: &Query, out: &mut Vec<Violation>) {
    let _ = ctx;
    let _ = out;
}

/// Checks for complexity metrics.
pub fn check_metrics(ctx: &CheckContext, complexity_query: &Query, out: &mut Vec<Violation>) {
    traverse_nodes(ctx, |node| {
        if node.kind().contains("function") || node.kind().contains("method") {
            validate_arity(node, ctx.config.max_function_args, out);
            validate_depth(node, ctx.config.max_nesting_depth, out);
            validate_complexity(
                node,
                ctx.source,
                complexity_query,
                ctx.config.max_cyclomatic_complexity,
                out,
            );
        }
    });
}

fn validate_arity(node: Node, max: usize, out: &mut Vec<Violation>) {
    let args = metrics::count_arguments(node);
    if args > max {
        out.push(Violation {
            row: node.start_position().row,
            message: format!(
                "High Arity: Function takes {args} arguments (Max: {max}). Use a Struct."
            ),
            law: "LAW OF COMPLEXITY",
        });
    }
}

fn validate_depth(node: Node, max: usize, out: &mut Vec<Violation>) {
    let depth = metrics::calculate_max_depth(node);
    if depth > max {
        out.push(Violation {
            row: node.start_position().row,
            message: format!("Deep Nesting: Max depth is {depth} (Max: {max}). Extract logic."),
            law: "LAW OF COMPLEXITY",
        });
    }
}

fn validate_complexity(
    node: Node,
    source: &str,
    query: &Query,
    max: usize,
    out: &mut Vec<Violation>,
) {
    let score = metrics::calculate_complexity(node, source, query);
    if score > max {
        out.push(Violation {
            row: node.start_position().row,
            message: format!("High Complexity: Score is {score} (Max: {max}). Hard to test."),
            law: "LAW OF COMPLEXITY",
        });
    }
}

/// Checks for banned constructs.
/// # Errors
/// Returns `Ok`.
#[allow(clippy::unnecessary_wraps)]
pub fn check_banned(
    ctx: &CheckContext,
    banned_query: &Query,
    out: &mut Vec<Violation>,
) -> Result<()> {
    let mut cursor = QueryCursor::new();
    for m in cursor.matches(banned_query, ctx.root, ctx.source.as_bytes()) {
        let node = m.captures[0].node;
        out.push(Violation {
            row: node.start_position().row,
            message: "Explicit 'unwrap()' call detected. Use 'expect', 'unwrap_or', or '?'.".into(),
            law: "LAW OF PARANOIA",
        });
    }
    Ok(())
}

fn traverse_nodes<F>(ctx: &CheckContext, mut cb: F)
where
    F: FnMut(Node),
{
    let mut cursor = ctx.root.walk();
    loop {
        cb(cursor.node());
        if !step_cursor(&mut cursor) {
            break;
        }
    }
}

fn step_cursor(cursor: &mut TreeCursor) -> bool {
    if cursor.goto_first_child() {
        return true;
    }
    while !cursor.goto_next_sibling() {
        if !cursor.goto_parent() {
            return false;
        }
    }
    true
}
</file>

<file path="src/clipboard.rs">
// src/clipboard.rs
use anyhow::Result;
use std::process::Command;

/// Copies text to the system clipboard.
///
/// # Errors
/// Returns error if the system clipboard command fails or is missing.
pub fn copy_to_clipboard(text: &str) -> Result<()> {
    perform_copy(text)
}

#[cfg(target_os = "macos")]
fn perform_copy(text: &str) -> Result<()> {
    use std::io::Write;
    let mut child = Command::new("pbcopy")
        .stdin(std::process::Stdio::piped())
        .spawn()?;
    if let Some(mut stdin) = child.stdin.take() {
        stdin.write_all(text.as_bytes())?;
    }
    child.wait()?;
    Ok(())
}

#[cfg(target_os = "linux")]
fn perform_copy(text: &str) -> Result<()> {
    use std::io::Write;
    let mut child = Command::new("xclip")
        .args(["-selection", "clipboard"])
        .stdin(std::process::Stdio::piped())
        .spawn()?;
    if let Some(mut stdin) = child.stdin.take() {
        stdin.write_all(text.as_bytes())?;
    }
    child.wait()?;
    Ok(())
}

#[cfg(target_os = "windows")]
fn perform_copy(text: &str) -> Result<()> {
    use std::io::Write;
    let mut child = Command::new("clip")
        .stdin(std::process::Stdio::piped())
        .spawn()?;
    if let Some(mut stdin) = child.stdin.take() {
        stdin.write_all(text.as_bytes())?;
    }
    child.wait()?;
    Ok(())
}

#[cfg(not(any(target_os = "macos", target_os = "linux", target_os = "windows")))]
fn perform_copy(_text: &str) -> Result<()> {
    use anyhow::anyhow;
    Err(anyhow!("Clipboard not supported on this OS"))
}
</file>

<file path="src/config.rs">
// src/config.rs
use crate::error::Result;
use regex::Regex;
use serde::Deserialize;
use std::collections::HashMap;
use std::fs;
use std::path::Path;

#[derive(Debug, Clone, Deserialize)]
pub struct RuleConfig {
    #[serde(default = "default_max_tokens")]
    pub max_file_tokens: usize,
    #[serde(default = "default_max_complexity")]
    pub max_cyclomatic_complexity: usize,
    #[serde(default = "default_max_depth")]
    pub max_nesting_depth: usize,
    #[serde(default = "default_max_args")]
    pub max_function_args: usize,
    #[serde(default = "default_max_words")]
    pub max_function_words: usize,
    #[serde(default)]
    pub ignore_naming_on: Vec<String>,
}

impl Default for RuleConfig {
    fn default() -> Self {
        Self {
            max_file_tokens: default_max_tokens(),
            max_cyclomatic_complexity: default_max_complexity(),
            max_nesting_depth: default_max_depth(),
            max_function_args: default_max_args(),
            max_function_words: default_max_words(),
            ignore_naming_on: Vec::new(),
        }
    }
}

const fn default_max_tokens() -> usize {
    2000
}
const fn default_max_complexity() -> usize {
    10
}
const fn default_max_depth() -> usize {
    4
}
const fn default_max_args() -> usize {
    5
}
const fn default_max_words() -> usize {
    3
}

#[derive(Debug, Clone, Deserialize, Default)]
pub struct WardenToml {
    #[serde(default)]
    pub rules: RuleConfig,
    #[serde(default)]
    pub commands: HashMap<String, String>,
}

#[derive(Debug, Clone)]
pub enum GitMode {
    Auto,
    Yes,
    No,
}

#[derive(Debug, Clone)]
pub struct Config {
    pub git_mode: GitMode,
    pub include_patterns: Vec<Regex>,
    pub exclude_patterns: Vec<Regex>,
    pub code_only: bool,
    pub verbose: bool,
    pub rules: RuleConfig,
    pub commands: HashMap<String, String>,
}

impl Default for Config {
    fn default() -> Self {
        Self::new()
    }
}

impl Config {
    #[must_use]
    pub fn new() -> Self {
        Self {
            git_mode: GitMode::Auto,
            include_patterns: Vec::new(),
            exclude_patterns: Vec::new(),
            code_only: false,
            verbose: false,
            rules: RuleConfig::default(),
            commands: HashMap::new(),
        }
    }

    /// Validates configuration.
    /// # Errors
    /// Returns `Ok` if valid.
    pub fn validate(&self) -> Result<()> {
        Ok(())
    }

    pub fn load_local_config(&mut self) {
        self.load_ignore_file();
        self.load_toml_config();
    }

    fn load_ignore_file(&mut self) {
        if let Ok(content) = fs::read_to_string(".wardenignore") {
            for line in content.lines() {
                self.process_ignore_line(line);
            }
        }
    }

    fn process_ignore_line(&mut self, line: &str) {
        let trimmed = line.trim();
        if trimmed.is_empty() || trimmed.starts_with('#') {
            return;
        }
        if let Ok(re) = Regex::new(trimmed) {
            self.exclude_patterns.push(re);
        }
    }

    fn load_toml_config(&mut self) {
        if Path::new("warden.toml").exists() {
            if let Ok(content) = fs::read_to_string("warden.toml") {
                self.parse_toml(&content);
            }
        }
    }

    fn parse_toml(&mut self, content: &str) {
        if let Ok(parsed) = toml::from_str::<WardenToml>(content) {
            self.rules = parsed.rules;
            self.commands = parsed.commands;
            if self.verbose {
                println!("üîß Loaded warden.toml");
            }
        }
    }
}

pub const PRUNE_DIRS: &[&str] = &[
    ".git",
    ".svn",
    ".hg",
    "node_modules",
    "target",
    "dist",
    "build",
    "out",
    "gen",
    ".venv",
    "venv",
    ".tox",
    "__pycache__",
    "coverage",
    "vendor",
    "Cargo.lock",
    "package-lock.json",
    "pnpm-lock.yaml",
    "yarn.lock",
    "bun.lockb",
    "go.sum",
    "Gemfile.lock",
    "tests",
    "test",
    "spec",
    "docs",
    "examples",
    "fixtures",
];
pub const BIN_EXT_PATTERN: &str =
    r"(?i)\.(png|jpg|gif|svg|ico|webp|woff2?|ttf|pdf|mp4|zip|gz|tar|exe|dll|so|dylib|class|pyc)$";
pub const SECRET_PATTERN: &str =
    r"(?i)(^\.?env(\..*)?$|/\.?env(\..*)?$|(^|/)(id_rsa|id_ed25519|.*\.(pem|p12|key|pfx))$)";
pub const CODE_EXT_PATTERN: &str = r"(?i)\.(rs|go|py|js|jsx|ts|tsx|java|c|cpp|h|hpp|cs|php|rb|sh|sql|html|css|scss|json|toml|yaml|md)$";
pub const CODE_BARE_PATTERN: &str = r"(?i)(Makefile|Dockerfile|CMakeLists\.txt)$";
</file>

<file path="src/detection.rs">
// src/detection.rs
use crate::error::Result;
use std::collections::HashSet;
use std::fmt;
use std::path::Path;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum BuildSystemType {
    Rust,
    Node,
    Python,
    Go,
    CMake,
    Conan,
}

impl fmt::Display for BuildSystemType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "{self:?}")
    }
}

#[derive(Default)]
pub struct Detector;

impl Detector {
    #[must_use]
    pub fn new() -> Self {
        Self
    }

    /// Detects build systems.
    /// # Errors
    /// Returns `Ok`.
    pub fn detect_build_systems(
        &self,
        files: &[std::path::PathBuf],
    ) -> Result<Vec<BuildSystemType>> {
        let mut detected = HashSet::new();
        for file in files {
            check_file(file, &mut detected);
        }
        Ok(detected.into_iter().collect())
    }
}

fn check_file(path: &Path, set: &mut HashSet<BuildSystemType>) {
    if let Some(name) = path.file_name().and_then(|n| n.to_str()) {
        if check_cmake(path, set) {
            return;
        }
        check_common(name, set);
    }
}

fn check_cmake(path: &Path, set: &mut HashSet<BuildSystemType>) -> bool {
    if path
        .extension()
        .is_some_and(|e| e.eq_ignore_ascii_case("cmake"))
    {
        set.insert(BuildSystemType::CMake);
        return true;
    }
    false
}

const COMMON_CONFIGS: &[(&str, BuildSystemType)] = &[
    ("Cargo.toml", BuildSystemType::Rust),
    ("package.json", BuildSystemType::Node),
    ("requirements.txt", BuildSystemType::Python),
    ("pyproject.toml", BuildSystemType::Python),
    ("Pipfile", BuildSystemType::Python),
    ("go.mod", BuildSystemType::Go),
    ("CMakeLists.txt", BuildSystemType::CMake),
    ("conanfile.txt", BuildSystemType::Conan),
    ("conanfile.py", BuildSystemType::Conan),
];

fn check_common(name: &str, set: &mut HashSet<BuildSystemType>) {
    for (file, sys) in COMMON_CONFIGS {
        if name == *file {
            set.insert(*sys);
            return;
        }
    }
}
</file>

<file path="src/enumerate.rs">
// warden:ignore
use crate::config::{Config, PRUNE_DIRS};
use crate::error::{Result, WardenError};
use std::path::PathBuf;
use std::process::Command;
use walkdir::WalkDir;

pub struct FileEnumerator {
    config: Config,
}

impl FileEnumerator {
    #[must_use]
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    /// Enumerates files based on configuration.
    ///
    /// # Errors
    ///
    /// Returns error if `git` fails in Git mode.
    pub fn enumerate(&self) -> Result<Vec<PathBuf>> {
        use crate::config::GitMode;

        match self.config.git_mode {
            GitMode::Yes => {
                if !Self::in_git_repo() {
                    return Err(WardenError::NotInGitRepo);
                }
                // Fixed: Self::filter_paths
                Ok(Self::filter_paths(Self::git_ls_files()?))
            }
            GitMode::No => Ok(self.walk_all_files()),
            GitMode::Auto => {
                if Self::in_git_repo() {
                    if let Ok(files) = Self::git_ls_files() {
                        // Fixed: Self::filter_paths
                        return Ok(Self::filter_paths(files));
                    }
                }
                Ok(self.walk_all_files())
            }
        }
    }

    // Fixed: Removed &self
    fn filter_paths(paths: Vec<PathBuf>) -> Vec<PathBuf> {
        paths
            .into_iter()
            .filter(|p| {
                for part in p.components() {
                    if let Some(s) = part.as_os_str().to_str() {
                        if PRUNE_DIRS.contains(&s) {
                            return false;
                        }
                    }
                }
                true
            })
            .collect()
    }

    fn in_git_repo() -> bool {
        let out = Command::new("git")
            .arg("rev-parse")
            .arg("--is-inside-work-tree")
            .output();

        matches!(out, Ok(o) if o.status.success())
    }

    fn git_ls_files() -> Result<Vec<PathBuf>> {
        let out = Command::new("git")
            .arg("ls-files")
            .arg("-z")
            .arg("--exclude-standard")
            .output()?;

        if !out.status.success() {
            return Err(WardenError::Other(format!(
                "git ls-files failed: exit {}",
                out.status
            )));
        }

        let mut paths = Vec::new();
        for chunk in out.stdout.split(|b| *b == 0) {
            if chunk.is_empty() {
                continue;
            }
            let s = String::from_utf8_lossy(chunk);
            paths.push(PathBuf::from(s.as_ref()));
        }
        Ok(paths)
    }

    fn walk_all_files(&self) -> Vec<PathBuf> {
        let mut paths = Vec::new();
        let mut errors = Vec::new();

        let walker = WalkDir::new(".").follow_links(false).into_iter();

        for item in walker.filter_entry(|e| {
            let name = e.file_name().to_string_lossy();
            // WalkDir filtering allows us to skip descending into "node_modules" entirely
            !PRUNE_DIRS.iter().any(|p| name == *p)
        }) {
            let entry = match item {
                Ok(e) => e,
                Err(e) => {
                    errors.push(format!("walkdir: {e}"));
                    continue;
                }
            };

            if entry.file_type().is_file() {
                let p = entry.path().strip_prefix(".").unwrap_or(entry.path());
                paths.push(p.to_path_buf());
            }
        }

        if !errors.is_empty() && self.config.verbose {
            eprintln!(
                "WARN: Encountered {} errors during file walk:",
                errors.len()
            );
            for (i, err) in errors.iter().take(5).enumerate() {
                eprintln!("  {}. {}", i + 1, err);
            }
        }

        paths
    }
}
</file>

<file path="src/error.rs">
// src/error.rs
use std::path::PathBuf;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum WardenError {
    #[error("I/O error: {source} (path: {path})")]
    Io {
        source: std::io::Error,
        path: PathBuf,
    },

    #[error("Not inside a Git repository")]
    NotInGitRepo,

    #[error("Regex error: {0}")]
    Regex(#[from] regex::Error),

    #[error("Generic error: {0}")]
    Other(String),
}

pub type Result<T> = std::result::Result<T, WardenError>;

// Allow `?` on std::io::Error by converting to WardenError::Io with unknown path.
impl From<std::io::Error> for WardenError {
    fn from(source: std::io::Error) -> Self {
        WardenError::Io {
            source,
            path: PathBuf::from("<unknown>"),
        }
    }
}

// Gracefully convert WalkDir errors
impl From<walkdir::Error> for WardenError {
    fn from(e: walkdir::Error) -> Self {
        WardenError::Other(e.to_string())
    }
}
</file>

<file path="src/filter.rs">
// src/filter.rs
use crate::config::{Config, BIN_EXT_PATTERN, CODE_BARE_PATTERN, CODE_EXT_PATTERN, SECRET_PATTERN};
use crate::error::Result;
use regex::Regex;
use std::path::Path;

pub struct FileFilter {
    config: Config,
    bin_ext_re: Regex,
    secret_re: Regex,
    code_ext_re: Option<Regex>,
    code_bare_re: Option<Regex>,
}

impl FileFilter {
    /// Creates a new filter.
    /// # Errors
    /// Returns error on invalid regex.
    pub fn new(config: &Config) -> Result<Self> {
        Ok(Self {
            config: config.clone(),
            bin_ext_re: Regex::new(BIN_EXT_PATTERN)?,
            secret_re: Regex::new(SECRET_PATTERN)?,
            code_ext_re: if config.code_only {
                Some(Regex::new(CODE_EXT_PATTERN)?)
            } else {
                None
            },
            code_bare_re: if config.code_only {
                Some(Regex::new(CODE_BARE_PATTERN)?)
            } else {
                None
            },
        })
    }

    #[must_use]
    pub fn filter(&self, files: Vec<std::path::PathBuf>) -> Vec<std::path::PathBuf> {
        files.into_iter().filter(|p| self.should_keep(p)).collect()
    }

    fn should_keep(&self, path: &Path) -> bool {
        let s = path.to_string_lossy().replace('\\', "/");
        if self.is_ignored(&s) {
            return false;
        }
        if self.config.code_only && !self.is_code(&s) {
            return false;
        }
        self.is_included(&s)
    }

    fn is_ignored(&self, path: &str) -> bool {
        if self.secret_re.is_match(path) {
            return true;
        }
        if self.bin_ext_re.is_match(path) {
            return true;
        }
        if self
            .config
            .exclude_patterns
            .iter()
            .any(|p| p.is_match(path))
        {
            return true;
        }
        false
    }

    fn is_included(&self, path: &str) -> bool {
        self.config.include_patterns.is_empty()
            || self
                .config
                .include_patterns
                .iter()
                .any(|p| p.is_match(path))
    }

    fn is_code(&self, path: &str) -> bool {
        match (&self.code_ext_re, &self.code_bare_re) {
            (Some(ext), Some(bare)) => ext.is_match(path) || bare.is_match(path),
            _ => true,
        }
    }
}
</file>

<file path="src/heuristics.rs">
// warden:ignore
use crate::config::{CODE_BARE_PATTERN, CODE_EXT_PATTERN};
use regex::Regex;
use std::collections::HashMap;
use std::fs;
use std::path::Path;
use std::sync::LazyLock;

// --- Configuration Constants for Heuristics ---
const MIN_TEXT_ENTROPY: f64 = 3.5;
const MAX_TEXT_ENTROPY: f64 = 5.5;

const BUILD_SYSTEM_PAMPS: &[&str] = &[
    "find_package",
    "add_executable",
    "target_link_libraries",
    "cmake_minimum_required",
    "project(",
    "add-apt-repository",
    "conanfile.py",
    "dependency",
    "require",
    "include",
    "import",
    "version",
    "dependencies",
];

// Pre-compiled regexes for known code files
static CODE_EXT_RE: LazyLock<Regex> = LazyLock::new(|| Regex::new(CODE_EXT_PATTERN).unwrap());
static CODE_BARE_RE: LazyLock<Regex> = LazyLock::new(|| Regex::new(CODE_BARE_PATTERN).unwrap());

pub struct HeuristicFilter;

impl HeuristicFilter {
    #[must_use]
    pub fn new() -> Self {
        Self
    }

    #[must_use]
    pub fn filter(&self, files: Vec<std::path::PathBuf>) -> Vec<std::path::PathBuf> {
        files
            .into_iter()
            .filter(|path| Self::should_keep(path))
            .collect()
    }

    fn should_keep(path: &Path) -> bool {
        let path_str = path.to_string_lossy();

        if CODE_EXT_RE.is_match(&path_str) || CODE_BARE_RE.is_match(&path_str) {
            return true;
        }

        if let Ok(entropy) = calculate_entropy(path) {
            if !(MIN_TEXT_ENTROPY..=MAX_TEXT_ENTROPY).contains(&entropy) {
                return false;
            }
        } else {
            return false;
        }

        if let Ok(content) = fs::read_to_string(path) {
            let lower_content = content.to_lowercase();
            for pamp in BUILD_SYSTEM_PAMPS {
                if lower_content.contains(pamp) {
                    return true;
                }
            }
        }

        true
    }
}

impl Default for HeuristicFilter {
    fn default() -> Self {
        Self::new()
    }
}

fn calculate_entropy(path: &Path) -> std::io::Result<f64> {
    let bytes = fs::read(path)?;
    if bytes.is_empty() {
        return Ok(0.0);
    }

    let mut freq_map = HashMap::new();
    for &byte in &bytes {
        *freq_map.entry(byte).or_insert(0) += 1;
    }

    // Suppress cast precision loss for 64-bit length; entropy approximation is fine.
    #[allow(clippy::cast_precision_loss)]
    let len = bytes.len() as f64;

    let entropy = freq_map.values().fold(0.0, |acc, &count| {
        let probability = f64::from(count) / len;
        acc - probability * probability.log2()
    });

    Ok(entropy)
}
</file>

<file path="src/lib.rs">
// src/lib.rs
pub mod analysis;
pub mod apply;
pub mod checks;
pub mod clipboard;
pub mod config;
pub mod detection;
pub mod enumerate;
pub mod error;
pub mod filter;
pub mod heuristics;
pub mod metrics;
pub mod prompt;
pub mod reporting;
pub mod rules;
pub mod tokens;
pub mod tui;
pub mod types;
</file>

<file path="src/metrics.rs">
// warden:ignore
use tree_sitter::{Node, Query, QueryCursor};

/// Calculates the nesting depth of a node.
///
/// # Returns
/// The maximum depth of control structures within the node.
#[must_use]
pub fn calculate_max_depth(node: Node) -> usize {
    let mut max_depth = 0;
    let mut cursor = node.walk();

    // We start at 0 relative to function body
    for child in node.children(&mut cursor) {
        if child.kind().contains("block") || child.kind().contains("body") {
            max_depth = std::cmp::max(max_depth, walk_depth(child, 0));
        }
    }
    max_depth
}

fn walk_depth(node: Node, current: usize) -> usize {
    let mut max = current;
    let mut cursor = node.walk();

    for child in node.children(&mut cursor) {
        let kind = child.kind();
        // Uses matches! macro to reduce Cyclomatic Complexity score
        // (This replaces the massive if/else chain)
        if matches!(
            kind,
            "if_expression"
                | "match_expression"
                | "for_expression"
                | "while_expression"
                | "loop_expression"
                | "if_statement"
                | "for_statement"
                | "for_in_statement"
                | "while_statement"
                | "do_statement"
                | "switch_case"
                | "catch_clause"
                | "try_statement"
        ) {
            max = std::cmp::max(max, walk_depth(child, current + 1));
        } else {
            max = std::cmp::max(max, walk_depth(child, current));
        }
    }
    max
}

/// Calculates `McCabe` Cyclomatic Complexity.
#[must_use]
pub fn calculate_complexity(node: Node, source: &str, query: &Query) -> usize {
    let mut cursor = QueryCursor::new();
    // Base complexity is 1
    let mut complexity = 1;
    for _ in cursor.matches(query, node, source.as_bytes()) {
        complexity += 1;
    }
    complexity
}

/// Counts named arguments/parameters.
#[must_use]
pub fn count_arguments(node: Node) -> usize {
    let mut cursor = node.walk();
    for child in node.children(&mut cursor) {
        if child.kind().contains("parameter") || child.kind().contains("argument") {
            return child.named_child_count();
        }
    }
    0
}
</file>

<file path="src/prompt.rs">
// src/prompt.rs
use crate::config::RuleConfig;
use anyhow::Result;

pub struct PromptGenerator {
    config: RuleConfig,
}

impl PromptGenerator {
    #[must_use]
    pub fn new(config: RuleConfig) -> Self {
        Self { config }
    }

    /// Generates the full system prompt.
    ///
    /// # Errors
    /// This function does not currently error but returns Result for API consistency.
    pub fn generate(&self) -> Result<String> {
        Ok(self.build_system_prompt())
    }

    /// Wraps the header for context packs.
    ///
    /// # Errors
    /// This function does not currently error but returns Result for API consistency.
    pub fn wrap_header(&self) -> Result<String> {
        Ok(self.build_system_prompt())
    }

    /// Generates a short reminder prompt.
    ///
    /// # Errors
    /// This function does not currently error but returns Result for API consistency.
    pub fn generate_reminder(&self) -> Result<String> {
        Ok(self.build_reminder())
    }

    fn build_system_prompt(&self) -> String {
        let tokens = self.config.max_file_tokens;
        let complexity = self.config.max_cyclomatic_complexity;
        let depth = self.config.max_nesting_depth;
        let args = self.config.max_function_args;
        let output_format = build_output_format();

        format!(
            r"üõ°Ô∏è SYSTEM MANDATE: THE WARDEN PROTOCOL
ROLE: High-Integrity Systems Architect (NASA/JPL Standard).
CONTEXT: You are coding inside a strict environment enforced by Warden.

THE 3 LAWS (Non-Negotiable):

1. LAW OF ATOMICITY
   - Files: MUST be < {tokens} tokens.
   - Action: Split immediately if larger.

2. LAW OF COMPLEXITY
   - Cyclomatic Complexity: MUST be ‚â§ {complexity} per function.
   - Nesting Depth: MUST be ‚â§ {depth} levels.
   - Function Arguments: MUST be ‚â§ {args} parameters.

3. LAW OF PARANOIA
   - Use Result<T, E> for I/O and fallible operations.
   - NO .unwrap() or .expect() calls.

{output_format}
"
        )
    }

    fn build_reminder(&self) -> String {
        let tokens = self.config.max_file_tokens;
        let complexity = self.config.max_cyclomatic_complexity;
        let depth = self.config.max_nesting_depth;
        let args = self.config.max_function_args;

        format!(
            r"WARDEN CONSTRAINTS:
‚ñ° Files < {tokens} tokens
‚ñ° Complexity ‚â§ {complexity}
‚ñ° Nesting ‚â§ {depth}
‚ñ° Args ‚â§ {args}
‚ñ° No .unwrap()
‚ñ° Use <delivery> + <file> tags"
        )
    }
}

fn build_output_format() -> &'static str {
    r"OUTPUT FORMAT (MANDATORY):

When providing code files, use this exact format:

1. Declare ALL files first:

<delivery>
path/to/file1.rs
path/to/file2.rs [NEW]
</delivery>

2. Provide EACH file:

<file path='path/to/file1.rs'>
[complete file contents]
</file>

RULES:
- Every file in <delivery> MUST have a matching <file> block
- Do NOT use markdown code blocks - use <file> tags only
- Do NOT truncate files
- Paths must match exactly

The `warden apply` command will REJECT incomplete deliveries."
}
</file>

<file path="src/reporting.rs">
// src/reporting.rs
use crate::types::{FileReport, ScanReport, Violation};
use anyhow::Result;
use colored::Colorize;

/// Prints the scan report to stdout.
///
/// # Errors
/// Returns Ok(()) normally.
pub fn print_report(report: &ScanReport) -> Result<()> {
    let failures = count_failures(report);

    // Filter and print only violating files
    report
        .files
        .iter()
        .filter(|f| !f.is_clean())
        .for_each(print_file_report);

    print_summary(report, failures);
    Ok(())
}

fn count_failures(report: &ScanReport) -> usize {
    report
        .files
        .iter()
        .filter(|f| !f.is_clean())
        .map(|f| f.violations.len())
        .sum()
}

fn print_file_report(file: &FileReport) {
    for v in &file.violations {
        print_violation(&file.path, v);
    }
}

fn print_violation(path: &std::path::Path, v: &Violation) {
    let filename = path.to_string_lossy();
    let line_num = v.row + 1;

    println!("{}: {}", "error".red().bold(), v.message.bold());
    println!("  {} {}:{}:1", "-->".blue(), filename, line_num);
    println!("   {}", "|".blue());
    println!(
        "   {} {}: Action required",
        "=".blue().bold(),
        v.law.white().bold()
    );
    println!();
}

fn print_summary(report: &ScanReport, failures: usize) {
    if failures > 0 {
        let msg = format!(
            "‚ùå Warden found {failures} violations in {}ms.",
            report.duration_ms
        );
        println!("{}", msg.red().bold());
    } else {
        let msg = format!(
            "‚úÖ All Clear. Scanned {} tokens in {}ms.",
            report.total_tokens, report.duration_ms
        );
        println!("{}", msg.green().bold());
    }
}
</file>

<file path="src/rules.rs">
use crate::analysis::Analyzer;
use crate::config::Config;
use crate::tokens::Tokenizer;
use crate::types::{FileReport, ScanReport, Violation};
use rayon::prelude::*;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::LazyLock;
use std::time::Instant;

static ANALYZER: LazyLock<Analyzer> = LazyLock::new(Analyzer::new);

pub struct RuleEngine {
    config: Config,
}

impl RuleEngine {
    #[must_use]
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    /// Scans a list of files and returns a structured report.
    ///
    /// # Errors
    ///
    /// Returns error if Rayon thread pool fails (unlikely).
    #[must_use]
    pub fn scan(&self, files: Vec<PathBuf>) -> ScanReport {
        let start = Instant::now();

        // Parallel scan
        let results: Vec<FileReport> = files
            .into_par_iter()
            .filter_map(|path| self.analyze_file(&path))
            .collect();

        let total_tokens = results.iter().map(|f| f.token_count).sum();
        let total_violations = results.iter().map(|f| f.violations.len()).sum();

        ScanReport {
            files: results,
            total_tokens,
            total_violations,
            duration_ms: start.elapsed().as_millis(),
        }
    }

    fn analyze_file(&self, path: &Path) -> Option<FileReport> {
        let content = fs::read_to_string(path).ok()?;

        if content.contains("// warden:ignore") || content.contains("# warden:ignore") {
            return None;
        }

        let filename = path.to_string_lossy();
        let mut violations = Vec::new();
        let token_count = Tokenizer::count(&content);

        // 1. Law of Atomicity
        if token_count > self.config.rules.max_file_tokens {
            violations.push(Violation {
                row: 0,
                message: format!(
                    "File size is {token_count} tokens (Limit: {})",
                    self.config.rules.max_file_tokens
                ),
                law: "LAW OF ATOMICITY",
            });
        }

        // 2. AST Analysis
        if let Some(ext) = path.extension().and_then(|s| s.to_str()) {
            let mut analysis_violations =
                ANALYZER.analyze(ext, &filename, &content, &self.config.rules);
            violations.append(&mut analysis_violations);
        }

        Some(FileReport {
            path: path.to_path_buf(),
            token_count,
            complexity_score: 0, // Future: aggregate function complexity here
            violations,
        })
    }
}
</file>

<file path="src/tokens.rs">
use std::sync::LazyLock;
use tiktoken_rs::CoreBPE;

// We use cl100k_base (GPT-4/3.5 turbo encoding) as the standard
static BPE: LazyLock<CoreBPE> =
    LazyLock::new(|| tiktoken_rs::cl100k_base().expect("Failed to load cl100k_base dictionary"));

pub struct Tokenizer;

impl Tokenizer {
    #[must_use]
    pub fn count(text: &str) -> usize {
        // EncodeOrdinary is faster as it ignores special tokens, which is fine for code
        BPE.encode_ordinary(text).len()
    }

    /// Returns true if the file exceeds the token limit
    #[must_use]
    pub fn exceeds_limit(text: &str, limit: usize) -> bool {
        Self::count(text) > limit
    }
}
</file>

<file path="src/tui/mod.rs">
pub mod state;
pub mod view;
</file>

<file path="src/tui/state.rs">
// src/tui/state.rs
use crate::types::{FileReport, ScanReport};
use anyhow::Result;
use crossterm::event::{self, Event, KeyCode};
use std::time::Duration;

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum SortMode {
    Path,
    Tokens,
    Violations,
}

pub struct App {
    pub report: ScanReport,
    pub view_indices: Vec<usize>,
    pub selected_index: usize,
    pub running: bool,
    pub sort_mode: SortMode,
    pub only_violations: bool,
}

impl App {
    #[must_use]
    pub fn new(report: ScanReport) -> Self {
        let mut app = Self {
            report,
            view_indices: Vec::new(),
            selected_index: 0,
            running: true,
            sort_mode: SortMode::Path,
            only_violations: false,
        };
        app.update_view();
        app
    }

    fn update_view(&mut self) {
        let mut indices: Vec<usize> = self
            .report
            .files
            .iter()
            .enumerate()
            .filter(|(_, f)| !self.only_violations || !f.is_clean())
            .map(|(i, _)| i)
            .collect();

        self.sort_indices(&mut indices);
        self.view_indices = indices;
        self.clamp_selection();
    }

    fn sort_indices(&self, indices: &mut [usize]) {
        let files = &self.report.files;
        indices.sort_by(|&a, &b| {
            let f1 = &files[a];
            let f2 = &files[b];
            match self.sort_mode {
                SortMode::Path => f1.path.cmp(&f2.path),
                SortMode::Tokens => f2.token_count.cmp(&f1.token_count),
                SortMode::Violations => f2.violations.len().cmp(&f1.violations.len()),
            }
        });
    }

    fn clamp_selection(&mut self) {
        if self.view_indices.is_empty() {
            self.selected_index = 0;
        } else if self.selected_index >= self.view_indices.len() {
            self.selected_index = self.view_indices.len() - 1;
        }
    }

    /// Runs TUI loop.
    /// # Errors
    /// Returns error on IO failure.
    pub fn run<B: ratatui::backend::Backend>(
        &mut self,
        terminal: &mut ratatui::Terminal<B>,
    ) -> Result<()> {
        while self.running {
            terminal.draw(|f| crate::tui::view::draw(f, self))?;
            self.process_event()?;
        }
        Ok(())
    }

    fn process_event(&mut self) -> Result<()> {
        if event::poll(Duration::from_millis(100))? {
            if let Event::Key(key) = event::read()? {
                self.handle_input(key.code);
            }
        }
        Ok(())
    }

    fn handle_input(&mut self, code: KeyCode) {
        if self.handle_nav(code) {
            return;
        }
        if self.handle_quit(code) {
            return;
        }
        self.handle_toggles(code);
    }

    fn handle_nav(&mut self, code: KeyCode) -> bool {
        match code {
            KeyCode::Up | KeyCode::Char('k') => {
                self.move_up();
                true
            }
            KeyCode::Down | KeyCode::Char('j') => {
                self.move_down();
                true
            }
            _ => false,
        }
    }

    fn handle_quit(&mut self, code: KeyCode) -> bool {
        if matches!(code, KeyCode::Char('q') | KeyCode::Esc) {
            self.running = false;
            return true;
        }
        false
    }

    fn handle_toggles(&mut self, code: KeyCode) {
        match code {
            KeyCode::Char('s') => self.cycle_sort(),
            KeyCode::Char('f') => self.toggle_filter(),
            _ => {}
        }
    }

    fn move_up(&mut self) {
        if self.selected_index > 0 {
            self.selected_index -= 1;
        }
    }

    fn move_down(&mut self) {
        if !self.view_indices.is_empty() && self.selected_index < self.view_indices.len() - 1 {
            self.selected_index += 1;
        }
    }

    fn cycle_sort(&mut self) {
        self.sort_mode = match self.sort_mode {
            SortMode::Path => SortMode::Tokens,
            SortMode::Tokens => SortMode::Violations,
            SortMode::Violations => SortMode::Path,
        };
        self.update_view();
    }

    fn toggle_filter(&mut self) {
        self.only_violations = !self.only_violations;
        self.update_view();
    }

    #[must_use]
    pub fn get_selected_file(&self) -> Option<&FileReport> {
        if let Some(&real_index) = self.view_indices.get(self.selected_index) {
            self.report.files.get(real_index)
        } else {
            None
        }
    }
}
</file>

<file path="src/tui/view/components.rs">
// src/tui/view/components.rs
use crate::tui::state::App;
use crate::types::FileReport;
use ratatui::layout::{Alignment, Constraint, Direction, Layout, Rect};
use ratatui::style::{Color, Modifier, Style};
use ratatui::text::{Line, Span};
use ratatui::widgets::{Block, Borders, Gauge, List, ListItem, Paragraph};
use ratatui::Frame;

pub fn draw_file_list(f: &mut Frame, app: &App, area: Rect) {
    let block = Block::default()
        .borders(Borders::ALL)
        .title(" üìÇ File List ");
    let items = build_list_items(app);

    let list = List::new(items).block(block).highlight_style(
        Style::default()
            .bg(Color::DarkGray)
            .add_modifier(Modifier::BOLD),
    );

    let mut state = ratatui::widgets::ListState::default();
    state.select(Some(app.selected_index));
    f.render_stateful_widget(list, area, &mut state);
}

fn build_list_items(app: &App) -> Vec<ListItem<'_>> {
    app.view_indices
        .iter()
        .map(|&idx| {
            let file = &app.report.files[idx];
            create_list_item(file)
        })
        .collect()
}

fn create_list_item(file: &FileReport) -> ListItem<'_> {
    let name = file.path.to_string_lossy();
    let is_clean = file.is_clean();
    let (color, icon) = if !is_clean {
        (Color::Red, "!")
    } else if file.token_count > 1000 {
        (Color::Yellow, "‚úì")
    } else {
        (Color::Green, "‚úì")
    };

    let bars = (file.token_count / 200).clamp(0, 10);
    let bar_vis = "I".repeat(bars);

    let content = Line::from(vec![
        Span::styled(
            format!("{icon} "),
            Style::default().fg(color).add_modifier(Modifier::BOLD),
        ),
        Span::raw(format!("{name:<30} ")),
        Span::styled(
            format!("{bar_vis:<10}"),
            Style::default().fg(Color::DarkGray),
        ),
    ]);
    ListItem::new(content)
}

#[allow(clippy::cast_precision_loss)]
pub fn draw_inspector(f: &mut Frame, app: &App, area: Rect) {
    let block = Block::default()
        .borders(Borders::ALL)
        .title(" üïµÔ∏è Inspector ");
    let inner = block.inner(area);
    f.render_widget(block, area);

    if let Some(file) = app.get_selected_file() {
        let layout = Layout::default()
            .direction(Direction::Vertical)
            .constraints(
                [
                    Constraint::Length(2),
                    Constraint::Length(6),
                    Constraint::Min(5),
                ]
                .as_ref(),
            )
            .split(inner);

        draw_header(f, file, layout[0]);
        draw_stats(f, file, layout[1]);
        draw_issues(f, file, layout[2]);
    } else {
        f.render_widget(
            Paragraph::new("No file selected").alignment(Alignment::Center),
            inner,
        );
    }
}

fn draw_header(f: &mut Frame, file: &FileReport, area: Rect) {
    let header = Paragraph::new(Line::from(vec![
        Span::styled("TARGET: ", Style::default().fg(Color::DarkGray)),
        Span::styled(
            file.path.to_string_lossy(),
            Style::default().add_modifier(Modifier::BOLD),
        ),
    ]));
    f.render_widget(header, area);
}

#[allow(clippy::cast_precision_loss)]
fn draw_stats(f: &mut Frame, file: &FileReport, area: Rect) {
    let chunks = Layout::default()
        .direction(Direction::Horizontal)
        .constraints([Constraint::Percentage(50), Constraint::Percentage(50)].as_ref())
        .split(area);

    let t_ratio = (file.token_count as f64 / 2000.0).clamp(0.0, 1.0);
    let t_gauge = Gauge::default()
        .block(Block::default().borders(Borders::NONE).title("Size"))
        .gauge_style(Style::default().fg(if t_ratio > 0.8 {
            Color::Red
        } else {
            Color::Green
        }))
        .ratio(t_ratio)
        .label(format!("{} toks", file.token_count));
    f.render_widget(t_gauge, chunks[0]);

    let v_count = file.violations.len();
    let v_ratio = (v_count as f64 / 5.0).clamp(0.0, 1.0);
    let v_gauge = Gauge::default()
        .block(Block::default().borders(Borders::NONE).title("Issues"))
        .gauge_style(Style::default().fg(if v_count > 0 {
            Color::Red
        } else {
            Color::Green
        }))
        .ratio(v_ratio)
        .label(format!("{v_count} Found"));
    f.render_widget(v_gauge, chunks[1]);
}

fn draw_issues(f: &mut Frame, file: &FileReport, area: Rect) {
    if file.is_clean() {
        let p = Paragraph::new("‚ú® Clean.")
            .style(Style::default().fg(Color::Green))
            .alignment(Alignment::Center);
        f.render_widget(p, area);
        return;
    }

    let items: Vec<ListItem> = file
        .violations
        .iter()
        .map(|v| {
            let header = Line::from(vec![
                Span::styled(
                    format!("[{}] ", v.law),
                    Style::default().fg(Color::Red).add_modifier(Modifier::BOLD),
                ),
                Span::raw(format!("Line {}", v.row + 1)),
            ]);
            let msg = Line::from(Span::styled(
                format!("  ‚îî‚îÄ {}", v.message),
                Style::default().fg(Color::White),
            ));
            ListItem::new(vec![header, msg, Line::from("")])
        })
        .collect();

    let list = List::new(items).block(Block::default().borders(Borders::TOP).title(" Violations "));
    f.render_widget(list, area);
}
</file>

<file path="src/tui/view/layout.rs">
// src/tui/view/layout.rs
use crate::tui::state::{App, SortMode};
use crate::tui::view::components;
use ratatui::layout::{Alignment, Constraint, Direction, Layout, Rect};
use ratatui::style::{Color, Modifier, Style};
use ratatui::text::{Line, Span};
use ratatui::widgets::{Block, Borders, Paragraph};
use ratatui::Frame;

pub fn render_dashboard(f: &mut Frame, app: &App, area: Rect) {
    let chunks = Layout::default()
        .direction(Direction::Vertical)
        .constraints(
            [
                Constraint::Length(3),
                Constraint::Min(10),
                Constraint::Length(1),
            ]
            .as_ref(),
        )
        .split(area);

    draw_header(f, app, chunks[0]);
    draw_main(f, app, chunks[1]);
    draw_footer(f, chunks[2]);
}

#[allow(clippy::cast_precision_loss)]
fn draw_header(f: &mut Frame, app: &App, area: Rect) {
    let (clean_count, total) = count_stats(app);
    let health = if total > 0 {
        (clean_count as f64 / total as f64) * 100.0
    } else {
        100.0
    };

    let info = build_info_string(app, total);
    let line = build_header_line(health, &info);

    f.render_widget(
        Paragraph::new(line)
            .block(Block::default().borders(Borders::ALL))
            .alignment(Alignment::Center),
        area,
    );
}

fn count_stats(app: &App) -> (usize, usize) {
    (
        app.report.files.iter().filter(|f| f.is_clean()).count(),
        app.report.files.len(),
    )
}

fn get_health_color(health: f64) -> Color {
    if health > 90.0 {
        return Color::Green;
    }
    if health > 70.0 {
        return Color::Yellow;
    }
    Color::Red
}

fn build_info_string(app: &App, total: usize) -> String {
    let sort_str = get_sort_label(app.sort_mode);
    let filter_str = get_filter_label(app.only_violations);
    format!(" FILES: {total} | SORT: {sort_str}{filter_str} ")
}

fn get_sort_label(mode: SortMode) -> &'static str {
    match mode {
        SortMode::Path => "NAME",
        SortMode::Tokens => "SIZE",
        SortMode::Violations => "ERRORS",
    }
}

fn get_filter_label(active: bool) -> &'static str {
    if active {
        " | FILTER: ERRORS"
    } else {
        ""
    }
}

fn build_header_line(health: f64, info: &str) -> Line<'_> {
    Line::from(vec![
        Span::styled(
            " üõ°Ô∏è WARDEN PROTOCOL ",
            Style::default()
                .fg(Color::Cyan)
                .add_modifier(Modifier::BOLD),
        ),
        Span::raw(" | "),
        Span::styled(
            format!("HEALTH: {health:.1}%"),
            Style::default().fg(get_health_color(health)),
        ),
        Span::raw(" |"),
        Span::raw(info),
    ])
}

fn draw_main(f: &mut Frame, app: &App, area: Rect) {
    let chunks = get_main_chunks(area);
    components::draw_file_list(f, app, chunks[0]);
    components::draw_inspector(f, app, chunks[1]);
}

fn get_main_chunks(area: Rect) -> std::rc::Rc<[Rect]> {
    Layout::default()
        .direction(Direction::Horizontal)
        .constraints([Constraint::Percentage(40), Constraint::Percentage(60)].as_ref())
        .split(area)
}

fn draw_footer(f: &mut Frame, area: Rect) {
    let text = " [s] Sort Mode | [f] Filter Errors | [j/k] Navigate | [q] Quit ";
    f.render_widget(
        Paragraph::new(text).style(Style::default().fg(Color::DarkGray).bg(Color::Black)),
        area,
    );
}
</file>

<file path="src/tui/view/mod.rs">
// src/tui/view/mod.rs
pub mod components;
pub mod layout;

use crate::tui::state::App;
use ratatui::Frame;

pub fn draw(f: &mut Frame, app: &App) {
    let area = f.area();
    layout::render_dashboard(f, app, area);
}
</file>

<file path="src/types.rs">
use std::path::PathBuf;

#[derive(Debug, Clone)]
pub struct Violation {
    pub row: usize,
    pub message: String,
    pub law: &'static str,
}

#[derive(Debug, Clone)]
pub struct FileReport {
    pub path: PathBuf,
    pub token_count: usize,
    pub complexity_score: usize,
    pub violations: Vec<Violation>,
}

impl FileReport {
    #[must_use]
    pub fn is_clean(&self) -> bool {
        self.violations.is_empty()
    }
}

#[derive(Debug, Clone, Default)]
pub struct ScanReport {
    pub files: Vec<FileReport>,
    pub total_tokens: usize,
    pub total_violations: usize,
    pub duration_ms: u128,
}
</file>

<file path="warden.toml">
# warden.toml
[rules]
max_file_tokens = 2000
max_cyclomatic_complexity = 4
max_nesting_depth = 2
max_function_args = 5
max_function_words = 5
ignore_naming_on = ["tests", "spec"]

[commands]
check = "cargo clippy --all-targets -- -D warnings -D clippy::pedantic"
</file>

