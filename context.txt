üõ°Ô∏è SYSTEM MANDATE: THE WARDEN PROTOCOL
ROLE: High-Integrity Systems Architect (NASA/JPL Standard).
CONTEXT: You are coding inside a strict environment enforced by Warden.

THE 3 LAWS (Non-Negotiable):

1. LAW OF ATOMICITY
   - Files: MUST be < 2000 tokens.
   - Action: Split immediately if larger.

2. LAW OF COMPLEXITY
   - Cyclomatic Complexity: MUST be ‚â§ 8 per function.
   - Nesting Depth: MUST be ‚â§ 3 levels.
   - Function Arguments: MUST be ‚â§ 5 parameters.

3. LAW OF PARANOIA
   - Use Result<T, E> for I/O and fallible operations.
   - NO .unwrap() or .expect() calls.

OUTPUT FORMAT (MANDATORY):

1. Explain the changes (Technical Plan) using NABLA PROTOCOL:
   - Must start with "GOAL:"
   - Must include "CHANGES:" list

‚àá‚àá‚àá PLAN ‚àá‚àá‚àá
GOAL: Refactor authentication module.
CHANGES:
1. Extract user validation to new file.
2. Update config parser.
‚àÜ‚àÜ‚àÜ

2. Declare the plan (Manifest) using NABLA PROTOCOL:

‚àá‚àá‚àá MANIFEST ‚àá‚àá‚àá
path/to/file1.rs
path/to/file2.rs [NEW]
‚àÜ‚àÜ‚àÜ

3. Provide EACH file using NABLA PROTOCOL:

‚àá‚àá‚àá path/to/file1.rs ‚àá‚àá‚àá
[file content]
‚àÜ‚àÜ‚àÜ

RULES:
- Do NOT use markdown code blocks (e.g. triple backticks) to wrap the file. The ‚àá‚àá‚àá delimiters ARE the fence.
- You MAY use markdown inside the file content.
- Every file in the manifest MUST have a matching ‚àá‚àá‚àá block.
- Paths must match exactly.
- Do NOT truncate files (No "// ...").


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
BEGIN CODEBASE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚àá‚àá‚àá .gitignore ‚àá‚àá‚àá
# Rust build artifacts
/target/
/docs/
/tests/
/Cargo.lock

# Logs and temp files
*.log
*.tmp
*.bak

# Generated AI pack and test fixtures
ai-pack/
tests/tmp/
tmp/
*.manifest.json

# Editor/OS files
.DS_Store
Thumbs.db
.idea/
.vscode/
*.swp
*.swo

# Git / OS cruft
*~
*.orig

# Node / frontend extras
node_modules/
dist/
build/
coverage/
.env

# Python extras
__pycache__/
.venv/
venv/

# Repomix or AI output
*.xml
*.jsonl

# Ignore everything inside /target/release except binaries we care about
!/target/release/saccade.exe
!/target/release/gauntlet.exe
chaos_examples/

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá Cargo.toml ‚àá‚àá‚àá
[package]
name = "warden"
version = "0.5.0"
edition = "2021"

[lib]
name = "warden_core"
path = "src/lib.rs"

[[bin]]
name = "warden"
path = "src/bin/warden.rs"

[dependencies]
anyhow = "1.0"
thiserror = "1.0"
regex = "1.10"
walkdir = "2.5"
clap = { version = "4.5", features = ["derive"] }
ignore = "0.4"
colored = "2.1"
rayon = "1.10"
once_cell = "1.19"
serde = { version = "1.0", features = ["derive"] }
toml = "0.8"
arboard = "3.4"

# THE BRAINS
tiktoken-rs = "0.5"

# UI / TUI
ratatui = "0.29"
crossterm = "0.28"

# Structural Parsing
tree-sitter = "0.20"
tree-sitter-rust = "0.20"
tree-sitter-python = "0.20"
tree-sitter-typescript = "0.20"
tree-sitter-javascript = "0.20"

[dev-dependencies]
tempfile = "3.10"
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá LICENSE ‚àá‚àá‚àá
MIT License

Copyright (c) 2025 Spencer Nunamaker

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá README.md ‚àá‚àá‚àá
# üõ°Ô∏è Warden Protocol

**Structural governance for AI-assisted development.**

> *"The rules are like the seat belts in a car: Initially, using them is perhaps a little uncomfortable, but after a while, it becomes second nature, and not using them is unimaginable."*
> ‚Äî Gerard J. Holzmann, NASA/JPL

Warden enforces **NASA "Power of 10" Rules** adapted for the AI coding era. It's not a style linter‚Äîit's a containment system that keeps AI-generated code verifiable, modular, and sane.

    cargo install --path .

---

## The Problem

You paste 50KB into Claude. It generates a 400-line function with 6 levels of nesting. Now you're debugging something neither you nor the AI can reason about.

AI-generated code **drifts**:
- Functions bloat
- Complexity creeps
- Context windows overflow
- Hallucinations compound

Warden stops this at the source.

---

## The 3 Laws

### 1. Law of Atomicity
Files must be **< 2000 tokens**.

Small files fit in context windows. Small files are verifiable. Small files can be taken to an AI in isolation and brought back‚Äîthey just slot in.

### 2. Law of Complexity
- **Cyclomatic Complexity:** ‚â§ 10 per function
- **Nesting Depth:** ‚â§ 3 levels
- **Function Arguments:** ‚â§ 5 parameters

These aren't style preferences. They're **containment protocols**. Low complexity bounds the hallucination surface. Shallow nesting prevents AI losing track of scope.

### 3. Law of Paranoia
- No `.unwrap()` or `.expect()` (Rust)
- Fallible operations must return `Result`

The type system is your ally. Don't let AI lie to the compiler.

---

## The Dream

Take any file to a fresh AI conversation. Work on it. Bring it back.

**It slots in perfectly. Every time. Guaranteed.**

This is the ultimate dream of Warden: modularity so strict that files become interchangeable, verifiable units.

---

## Quick Start

    cd your-project
    warden              # Scan for violations (auto-creates warden.toml)
    warden pack --prompt # Generate context.txt for AI

That's it. Warden detects your project type (Rust/Node/Python/Go) and configures itself.

---

## The Workflow

Warden is a closed-loop system for AI development.

### 1. Generate Context

    warden pack --prompt

Creates `context.txt` containing:
- Your codebase (filtered, deduplicated)
- The Warden Protocol system prompt
- Current violations (AI sees what to fix)
- Token count

### 2. Chat with AI

`context.txt` will be generated and applied to your clipboard. Paste the file into Claude/GPT/Gemini. Ask for changes.

The AI responds with structured output:

    ‚àá‚àá‚àá src/lib.rs ‚àá‚àá‚àá
    // complete file contents
    ‚àÜ‚àÜ‚àÜ
    
    ‚àá‚àá‚àá src/new_module.rs ‚àá‚àá‚àá
    // complete file contents
    ‚àÜ‚àÜ‚àÜ

### 3. Apply Changes

    warden apply

This:
- Extracts file blocks from clipboard
- **Validates paths** (blocks traversal, sensitive files, hidden files)
- **Rejects truncated output** (unbalanced braces, `// ...` markers)
- **Rejects markdown artifacts** (no fenced code blocks in source)
- Creates timestamped backup
- Writes files atomically
- On failure: copies AI-friendly error to clipboard

### 4. Verify

    warden          # Structural analysis
    warden check    # Run your linter (clippy, biome, ruff)

If violations exist, exit code is non-zero. CI-friendly.

### 5. Iterate

If `warden apply` fails, the error is already in your clipboard. Paste it back to AI, get corrected output, repeat.

---

## Commands

### Core Analysis & Validation
| Command | Description |
|---------|-------------|
| `warden` | Run structural scan (complexity, tokens, etc.) |
| `warden --ui` | Interactive TUI dashboard |
| `warden check` | Run configured linter (e.g., clippy, ruff) |
| `warden fix` | Run configured formatter |

### Context & Packaging
| Command | Description |
|---------|-------------|
| `warden pack` | Generate `context.txt` from codebase |
| `warden pack --prompt` | Include system prompt & violations |
| `warden pack --skeleton` | Export structure only (signatures) |
| `warden pack --git-only` | Only include files tracked by git |
| `warden pack --stdout` | Output to stdout instead of file |

### Application & Safety
| Command | Description |
|---------|-------------|
| `warden apply` | Apply AI response from clipboard |
| `warden apply --dry-run` | Validate output without writing to disk |

### Roadmap Management
| Command | Description |
|---------|-------------|
| `warden roadmap init` | Create new ROADMAP.md |
| `warden roadmap prompt` | Copy AI teaching prompt to clipboard |
| `warden roadmap apply` | Apply roadmap commands from clipboard |
| `warden roadmap show` | Display roadmap status tree |
| `warden roadmap tasks` | List tasks (filterable by pending/done) |

### Utilities
| Command | Description |
|---------|-------------|
| `warden --init` | Create/regenerate `warden.toml` |
| `warden prompt` | Print system prompt only |
| `warden prompt -c` | Copy system prompt to clipboard |

---

## Configuration

Warden auto-generates `warden.toml` based on project type:

**Rust:**

    [rules]
    max_file_tokens = 2000
    max_cyclomatic_complexity = 5
    max_nesting_depth = 2
    
    [commands]
    check = "cargo clippy --all-targets -- -D warnings -D clippy::pedantic"
    fix = "cargo fmt"

**Node/TypeScript:**

    [commands]
    check = "npx @biomejs/biome check src/"
    fix = "npx @biomejs/biome check --write src/"

**Python:**

    [commands]
    check = "ruff check ."
    fix = "ruff check --fix ."

### Tuning Strictness

Strict (for greenfield):

    [rules]
    max_file_tokens = 1500
    max_cyclomatic_complexity = 4
    max_nesting_depth = 2

Relaxed (for legacy adoption):

    [rules]
    max_file_tokens = 3000
    max_cyclomatic_complexity = 10
    max_nesting_depth = 4

---

## Safety Features

### Path Safety Validation

Warden blocks dangerous paths before they touch disk:

| Threat | Example | Status |
|--------|---------|--------|
| Directory traversal | `../etc/passwd` | Blocked |
| Absolute paths | `/etc/passwd`, `C:\Windows` | Blocked |
| Git internals | `.git/config` | Blocked |
| Secrets | `.env`, `.ssh/`, `.aws/` | Blocked |
| Hidden files | `.secrets`, `.private` | Blocked |

### Truncation Detection

AI output often gets cut off. Warden catches:
- Unbalanced `{}`, `[]`, `()`
- Truncation markers: `// ...`, `// rest of file`
- Files ending mid-statement

### Markdown Rejection

Chat interfaces love to wrap code in fenced blocks. Warden rejects any file containing triple backticks or tildes‚Äîthese corrupt source files.

### Atomic Backups

Before any write: `.warden_apply_backup/TIMESTAMP/`

Your original files are always preserved.

---

## The Nabla Format

XML tags get mangled by chat interfaces. Warden uses Unicode delimiters that never appear in real code:

    ‚àá‚àá‚àá path/to/file.rs ‚àá‚àá‚àá
    fn main() {
        println!("Hello");
    }
    ‚àÜ‚àÜ‚àÜ

- `‚àá‚àá‚àá` (nabla) opens a file block
- `‚àÜ‚àÜ‚àÜ` (delta) closes it
- Never interpreted as HTML
- Never rendered as markdown
- Trivial to parse

---

## TUI Dashboard

    warden --ui

| Key | Action |
|-----|--------|
| `j/k` | Navigate files |
| `s` | Cycle sort (name/size/errors) |
| `f` | Toggle error filter |
| `q` | Quit |

---

## Roadmap Management

Warden includes AI-friendly roadmap management. Instead of AI rewriting your entire roadmap, it sends surgical commands.

### The Workflow

1. Run `warden roadmap prompt`
2. Paste to AI, describe what changed
3. AI responds with commands:
```
===ROADMAP===
CHECK truncation-detection
ADD v0.5.0 "New feature" AFTER truncation-detection
NOTE auth-system "Needs refactor"
===END===
```

4. Run `warden roadmap apply`

### Commands

| Command | Example |
|---------|---------|
| `CHECK` | `CHECK task-name` |
| `UNCHECK` | `UNCHECK task-name` |
| `ADD` | `ADD v0.1.0 "New task"` |
| `ADD AFTER` | `ADD v0.1.0 "Task" AFTER other-task` |
| `DELETE` | `DELETE old-task` |
| `UPDATE` | `UPDATE task "New description"` |
| `NOTE` | `NOTE task "Implementation note"` |

Tasks are identified by slugified names. `Truncation detection` becomes `truncation-detection`.

---

## Coming Soon: The Contract Protocol

AI will declare intent before writing code. Warden verifies the output matches.

    ‚àá‚àá‚àá CONTRACT ‚àá‚àá‚àá
    GOAL: Refactor parser for clarity
    
    REFACTOR FN src/parser.rs:parse_header
        ASSERT complexity <= 4
        ASSERT depth <= 1
    
    CREATE STRUCT src/types.rs:Header
        ASSERT public == true
    
    UPDATE FILE src/lib.rs
        ASSERT tokens < 2000
    ‚àÜ‚àÜ‚àÜ

If AI hallucinates complex code or touches undeclared files, the contract fails. No human judgment needed‚Äîpass/fail.

---

## Why These Rules?

For humans, complexity limits are debatable style choices.

For AI, they're **containment protocols**:

| Metric | Human Value | AI Value |
|--------|-------------|----------|
| Cyclomatic Complexity | Debatable | **Critical** - bounds hallucination surface |
| Nesting Depth | Readability | **Critical** - AI loses scope tracking |
| Function Length | Preference | **Critical** - attention degrades |
| File Size | Organization | **Critical** - context economics |

We don't enforce low complexity because it makes "better" code. We enforce it because it makes **verifiable** code.

---

## Languages

Currently supported:
- **Rust** - Full analysis (complexity, nesting, arity, safety)
- **TypeScript/JavaScript** - Full analysis
- **Python** - Full analysis
- **Go** - Preliminary support

Coming soon: C/C++, Java/Kotlin

---

## Philosophy

Warden exists because AI-assisted development needs **constraints**, not suggestions.

The original Power of 10 rules were for life-critical systems where bugs kill people. We're not building flight software‚Äîbut we are building systems that must remain comprehensible through hundreds of AI-human iterations.

**Principles:**

1. **Reject bad input, don't fix it** ‚Äî Warden is a gatekeeper, not a fixer.

2. **Git is the undo system** ‚Äî Don't reinvent version control.

3. **Explicit > Magic** ‚Äî If AI doesn't follow format, fail loudly.

4. **Containment over craftsmanship** ‚Äî For AI, constraints aren't style. They're safety.

5. **Eat your own dogfood** ‚Äî Warden enforces its own rules on its own codebase.

---

## Self-Hosting

Warden is self-hosting. Run `warden` in this repo:

    ‚úÖ All Clear. Scanned 37586 tokens in 116ms.

The tool passes its own rules.

---

## License

MIT

---

## Links

- [Roadmap](ROADMAP.md)
- [NASA Power of 10 Rules](https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code)

---

*Complexity is the enemy. Warden is the checkpoint.*
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá ROADMAP.md ‚àá‚àá‚àá
# Warden Protocol Roadmap

## Philosophy

**The Two-Layer Model:**
1. **Files** (~2k tokens) - The organizational unit. Right-sized for context windows.
2. **Contracts** - The semantic unit. Machine-verifiable intent at symbol level.

**Why Constraints Matter for AI:**
- Cyclomatic complexity limits bound hallucination surface
- Nesting depth limits prevent AI losing track of scope  
- Function length limits fight attention degradation
- File size limits respect context window economics

These aren't style preferences. They're **containment protocols**.

---

## Current State: v0.4.1

- [x] Core loop: knit ‚Üí chat ‚Üí apply ‚Üí verify
- [x] Self-hosting (Warden passes its own rules)
- [x] Path safety validation (traversal, absolute, sensitive, hidden)
- [x] Markdown block rejection
- [x] Backup system

---

## v0.5.0 ‚Äî Bulletproof Apply
- [x] **Roadmap Integration (warden roadmap)**
- [x] **Update README with roadmap docs**
- [x] **Pack defaults to --prompt, --noprompt to disable**
- [x] **Pack copies file path to clipboard for attachment paste**
- [x] **TypeScript auto-detection uses biome**
- [x] **Integration tests for all features**
  *Integrated as core module with state-transition logic*

**Theme:** If it applies, it's valid. If it's invalid, it rejects hard.

### Validation Hardening

- [x] **Path safety validation**
  Blocks: `../` traversal, absolute paths, `.git/`, `.env`, `.ssh/`, `.aws/`, hidden files.

- [x] **Markdown block rejection**
  Rejects fenced code blocks in file content.

- [x] **Truncation detection**
  Reject obviously incomplete files:
  - Unbalanced braces/brackets
  - Truncation markers: `// ...`, `// rest of file`
  - Zero false positives logic
  - **Ignore Support**: `warden:ignore` bypasses checks for specific lines.

- [x] **Robust Delimiter Protocol (Nabla Format)**
  Replace fragile XML with high-entropy Unicode fences:
  
      ‚àá‚àá‚àá src/main.rs ‚àá‚àá‚àá
      fn main() {}
      ‚àÜ‚àÜ‚àÜ
  
  Benefits:
  - Never interpreted as HTML/Markdown
  - Never appears in real code
  - Trivial to regex
  - AI can't confuse output with format

### Workflow Enhancement

- [x] **Error injection in knit**
  When `knit --prompt` runs, append current violations.

- [x] **`warden apply --commit`**
  On success: `git add .` ‚Üí auto-generate commit message ‚Üí commit.
  
  *If it passes validation, commit it. Git is your undo.*
---

## v0.6.0 ‚Äî Context Intelligence

**Theme:** The Map vs. Territory problem.

### The Skeletonizer

Strip function bodies, keep signatures:

    // Full (Territory)
    pub fn process(data: &[u8]) -> Result<Output> {
        let parsed = parse(data)?;
        validate(&parsed)?;
        transform(parsed)
    }
    
    // Skeleton (Map)
    pub fn process(data: &[u8]) -> Result<Output> { ... }

- [x] **`knit --skeleton`** - All files skeletonized
  *Implemented using tree-sitter for RS, PY, TS*
- [ ] **`knit src/main.rs --smart`** - Full code for target + skeletons for rest

### Dependency Graphing

- [ ] Parse `mod`, `use`, `import`, `require` statements
- [ ] Build local dependency graph
- [ ] Auto-include dependencies in context

---

## v0.7.0 ‚Äî Verification & Safety

**Theme:** Beyond "it compiles."

### Feature Anchors (Anti-Lobotomy)
Prevent "accidental lobotomy" where AI refactors code and silently drops functionality.

- **Concept:** Explicitly declare "This code implements Feature X".
- **Mechanism:** `#[warden::feature("auth")]` attributes or `features.toml`.
- **Enforcement:** If a registered feature anchor disappears or its associated tests vanish, Warden halts.
- **Deprecation:** Explicit command `warden feature deprecate <name>` required to remove.

### Property-Based Testing

- [ ] **`warden gen-test <file>`**
  AI writes property tests (proptest/hypothesis), not unit tests.
  
      "Assert invariants. What must ALWAYS be true?"

### Function-Level Reporting

    src/engine.rs
    
      fn process_batch() [Line 45]
      ‚îú‚îÄ Complexity: 14 (max 5)
      ‚îú‚îÄ Depth: 5 (max 2)
      ‚îú‚îÄ Contributing factors:
      ‚îÇ   ‚îú‚îÄ 3 nested ifs (lines 52, 58, 61)
      ‚îÇ   ‚îî‚îÄ 2 complex match guards (lines 67, 89)
      ‚îî‚îÄ Suggestion: Extract inner match

### Incremental Scanning

- [ ] Track file mtimes in `.warden_cache`
- [ ] Use `git status` for changed files
- [ ] Full rescan on config change

---

## v0.8.0 ‚Äî Ecosystem

**Theme:** CI/CD integration.

- [ ] `warden --format json` - Machine-readable output
- [ ] SARIF output for GitHub Code Scanning
- [ ] `warden hook install` - Pre-commit hook
- [ ] GitHub Action for PR checks
- [ ] Documented exit codes

---

## v1.0.0 ‚Äî Release

- [ ] Published to crates.io
- [ ] Homebrew formula
- [ ] Scoop/Winget packages
- [ ] Documentation site
- [ ] Logo and branding

---

## Future

### AI-Native Linting
- Global state detection (`static mut`, singletons)
- Impure function warnings (returns value, takes no args)
- Deep inheritance check (> 1 level)

### Metrics Dashboard
SQLite backend. Complexity trends over time. Codebase health charts.

### Session Branches
`warden session start` ‚Üí timestamped branch
`warden apply --commit` ‚Üí atomic commits
`warden session merge` ‚Üí squash to main

---

## Not Doing

- **VS Code Extension** - IDE lock-in, maintenance burden
- **Watch mode** - Complexity without clear benefit
- **Markdown fallback parsing** - Enforce format discipline
- **"Smart" fixing** - Warden rejects, doesn't repair

---

## Principles

1. **Reject bad input, don't fix it**
   Warden is a gatekeeper, not a fixer.

2. **Git is the undo system**
   Don't reinvent version control.

3. **Explicit > Magic**
   If AI doesn't follow format, fail loudly.

4. **Containment over craftsmanship**
   For AI, constraints aren't style‚Äîthey're safety.

5. **Eat your own dogfood**
   Warden must pass its own rules.

6. **The dream: perfect modularity**
   Take any file to AI, bring it back, it slots in perfectly.
   Contracts make this verifiable.
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/analysis/ast.rs ‚àá‚àá‚àá
// src/analysis/ast.rs
use super::checks::{self, CheckContext};
use crate::config::RuleConfig;
use crate::types::Violation;
use tree_sitter::{Language, Parser, Query};

pub struct Analyzer {
    rust_naming: Query,
    rust_complexity: Query,
    rust_banned: Query,
    js_naming: Query,
    js_complexity: Query,
    py_naming: Query,
    py_complexity: Query,
}

impl Default for Analyzer {
    fn default() -> Self { ... }
}

impl Analyzer {
    #[must_use]
    pub fn new() -> Self { ... }

    #[must_use]
    pub fn analyze(
        &self,
        lang: &str,
        filename: &str,
        content: &str,
        config: &RuleConfig,
    ) -> Vec<Violation> { ... }

    fn select_language(&self, lang: &str) -> Option<LanguageQueries<'_>> { ... }

    fn queries_rust(&self) -> LanguageQueries<'_> { ... }

    fn queries_js(&self) -> LanguageQueries<'_> { ... }

    fn queries_python(&self) -> LanguageQueries<'_> { ... }

    fn run_analysis(
        queries: &LanguageQueries<'_>,
        filename: &str,
        content: &str,
        config: &RuleConfig,
    ) -> Vec<Violation> { ... }
}

struct LanguageQueries<'a> {
    language: Language,
    naming: &'a Query,
    complexity: &'a Query,
    banned: Option<&'a Query>,
}

fn compile_query(lang: Language, pattern: &str) -> Query { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/analysis/checks.rs ‚àá‚àá‚àá
// src/analysis/checks.rs
use super::metrics;
use crate::config::RuleConfig;
use crate::types::Violation;
use tree_sitter::{Node, Query, QueryCursor, QueryMatch, TreeCursor};

pub struct CheckContext<'a> {
    pub root: Node<'a>,
    pub source: &'a str,
    pub filename: &'a str,
    pub config: &'a RuleConfig,
}

/// Checks for naming violations (function name word count).
pub fn check_naming(ctx: &CheckContext, query: &Query, out: &mut Vec<Violation>) { ... }

fn count_words(name: &str) -> usize { ... }

fn is_ignored(filename: &str, patterns: &[String]) -> bool { ... }

/// Checks for complexity metrics (arity, depth, cyclomatic complexity).
pub fn check_metrics(ctx: &CheckContext, complexity_query: &Query, out: &mut Vec<Violation>) { ... }

fn validate_arity(node: Node, max: usize, out: &mut Vec<Violation>) { ... }

fn validate_depth(node: Node, max: usize, out: &mut Vec<Violation>) { ... }

fn validate_complexity(
    node: Node,
    source: &str,
    query: &Query,
    max: usize,
    out: &mut Vec<Violation>,
) { ... }

/// Checks for banned constructs (`.unwrap()` and `.expect()` calls).
pub fn check_banned(ctx: &CheckContext, banned_query: &Query, out: &mut Vec<Violation>) { ... }

fn process_banned_match(
    m: &QueryMatch,
    names: &[String],
    ctx: &CheckContext,
    out: &mut Vec<Violation>,
) { ... }

fn traverse_nodes<F>(ctx: &CheckContext, mut cb: F)
where
    F: FnMut(Node),
{ ... }

fn advance_cursor(cursor: &mut TreeCursor) -> bool { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/analysis/metrics.rs ‚àá‚àá‚àá
// src/analysis/metrics.rs
use tree_sitter::{Node, Query, QueryCursor};

/// Calculates the nesting depth of a node.
#[must_use]
pub fn calculate_max_depth(node: Node) -> usize { ... }

fn walk_depth(node: Node, current: usize) -> usize { ... }

/// Calculates `McCabe` Cyclomatic Complexity.
#[must_use]
pub fn calculate_complexity(node: Node, source: &str, query: &Query) -> usize { ... }

/// Counts named arguments/parameters.
#[must_use]
pub fn count_arguments(node: Node) -> usize { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/analysis/mod.rs ‚àá‚àá‚àá
// src/analysis/mod.rs
pub mod ast;
pub mod checks;
pub mod metrics;

use crate::config::Config;
use crate::tokens::Tokenizer;
use crate::types::{FileReport, ScanReport, Violation};
use ast::Analyzer;
use rayon::prelude::*;
use std::fs;
use std::path::{Path, PathBuf};
use std::sync::LazyLock;
use std::time::Instant;

static ANALYZER: LazyLock<Analyzer> = LazyLock::new(Analyzer::new);

pub struct RuleEngine {
    config: Config,
}

impl RuleEngine {
    #[must_use]
    pub fn new(config: Config) -> Self { ... }

    /// Scans a list of files and returns a structured report.
    #[must_use]
    pub fn scan(&self, files: Vec<PathBuf>) -> ScanReport { ... }

    fn analyze_file(&self, path: &Path) -> Option<FileReport> { ... }

    fn is_exempt_from_tokens(&self, filename: &str) -> bool { ... }
}
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/extractor.rs ‚àá‚àá‚àá
// src/apply/extractor.rs
use crate::apply::types::FileContent;
use anyhow::Result;
use regex::Regex;
use std::collections::HashMap;

/// Extracts the optional PLAN block.
#[must_use]
pub fn extract_plan(response: &str) -> Option<String> { ... }

/// Extracts file blocks using the Robust Delimiter Protocol (Nabla Format).
///
/// Format:
/// ‚àá‚àá‚àá path/to/file.rs ‚àá‚àá‚àá
/// [content]
/// ‚àÜ‚àÜ‚àÜ
///
/// # Errors
/// Returns error if regex compilation fails.
pub fn extract_files(response: &str) -> Result<HashMap<String, FileContent>> { ... }

fn process_block(
    response: &str,
    header_match: regex::Match,
    footer_re: &Regex,
    files: &mut HashMap<String, FileContent>,
) -> usize { ... }

fn skip_block(response: &str, start_pos: usize, footer_re: &Regex) -> usize { ... }

fn clean_nabla_content(raw: &str) -> String { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/git.rs ‚àá‚àá‚àá
// src/apply/git.rs
use anyhow::{anyhow, Result};
use std::process::Command;
use colored::Colorize;

/// Stages all files, commits with the plan, and pushes.
///
/// # Errors
/// Returns error if git commands fail.
pub fn commit_and_push(plan: Option<&str>) -> Result<()> { ... }

fn run_git(args: &[&str]) -> Result<()> { ... }

fn construct_message(plan: Option<&str>) -> String { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/manifest.rs ‚àá‚àá‚àá
// src/apply/manifest.rs
use crate::apply::types::{ManifestEntry, Operation};
use anyhow::Result;
use regex::Regex;

/// Parses the delivery manifest block.
/// Supports both Legacy XML and Nabla Protocol.
///
/// # Errors
/// Returns error if regex compilation fails.
pub fn parse_manifest(response: &str) -> Result<Option<Vec<ManifestEntry>>> { ... }

fn find_nabla_manifest(response: &str) -> Result<Option<(usize, usize)>> { ... }

fn find_legacy_manifest(response: &str) -> Result<Option<(usize, usize)>> { ... }

fn parse_manifest_lines(block: &str) -> Result<Vec<ManifestEntry>> { ... }

fn parse_manifest_line(line: &str, marker_re: &Regex) -> Option<ManifestEntry> { ... }

fn parse_operation(line: &str) -> (String, Operation) { ... }

fn extract_clean_path(raw: &str) -> String { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/messages.rs ‚àá‚àá‚àá
// src/apply/messages.rs
use crate::apply::types::ApplyOutcome;
use colored::Colorize;

pub fn print_outcome(outcome: &ApplyOutcome) { ... }

fn print_success(written: &[String], deleted: &[String], backed_up: bool) { ... }

fn print_validation_errors(errors: &[String], missing: &[String]) { ... }

fn print_ai_feedback(ai_message: &str) { ... }

#[must_use]
pub fn format_ai_rejection(missing: &[String], errors: &[String]) -> String { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/mod.rs ‚àá‚àá‚àá
// src/apply/mod.rs
pub mod extractor;
pub mod git;
pub mod manifest;
pub mod messages;
pub mod types;
pub mod validator;
pub mod writer;

use crate::clipboard;
use anyhow::{Context, Result};
use colored::Colorize;
use std::io::{self, Write};
use std::process::Command;
use types::{ApplyContext, ApplyOutcome, ExtractedFiles, Manifest};

/// Runs the apply command logic.
///
/// # Errors
/// Returns error if clipboard access fails.
pub fn run_apply(ctx: &ApplyContext) -> Result<ApplyOutcome> { ... }

pub fn print_result(outcome: &ApplyOutcome) { ... }

/// Processes input content directly.
///
/// # Errors
/// Returns error if extraction, write, or git operations fail.
pub fn process_input(content: &str, ctx: &ApplyContext) -> Result<ApplyOutcome> { ... }

fn ensure_consent(plan: Option<&str>, ctx: &ApplyContext) -> Result<bool> { ... }

fn validate_payload(content: &str) -> ApplyOutcome { ... }

fn apply_and_verify(content: &str, ctx: &ApplyContext, plan: Option<&str>) -> Result<ApplyOutcome> { ... }

fn verify_and_commit(outcome: &ApplyOutcome, ctx: &ApplyContext, plan: Option<&str>) -> Result<()> { ... }

fn verify_application(ctx: &ApplyContext) -> Result<bool> { ... }

fn run_check_command(cmd: &str) -> Result<bool> { ... }

fn validate_plan_structure(plan: &str) { ... }

fn confirm(prompt: &str) -> Result<bool> { ... }

fn parse_manifest_step(content: &str) -> Result<Manifest, String> { ... }

fn extract_files_step(content: &str) -> Result<ExtractedFiles, String> { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/types.rs ‚àá‚àá‚àá
// src/apply/types.rs
use crate::config::Config;
use std::collections::HashMap;

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum Operation {
    Update,
    New,
    Delete,
}

#[derive(Debug, Clone)]
pub struct ManifestEntry {
    pub path: String,
    pub operation: Operation,
}

#[derive(Debug, Clone)]
pub struct FileContent {
    pub content: String,
    pub line_count: usize,
}

#[derive(Debug)]
pub enum ApplyOutcome {
    Success {
        written: Vec<String>,
        deleted: Vec<String>,
        backed_up: bool,
    },
    ValidationFailure {
        errors: Vec<String>,
        missing: Vec<String>,
        ai_message: String,
    },
    ParseError(String),
    WriteError(String),
}

/// Context for the apply operation.
/// Connects project config with runtime flags.
pub struct ApplyContext<'a> {
    pub config: &'a Config,
    pub force: bool,   // Skips interactive confirmation (for tests/automation)
    pub dry_run: bool, // Skips disk writes (for tests)
}

impl<'a> ApplyContext<'a> {
    #[must_use]
    pub fn new(config: &'a Config) -> Self { ... }
}

// The manifest is just a list of entries
pub type Manifest = Vec<ManifestEntry>;

// The extracted files are mapped by path
pub type ExtractedFiles = HashMap<String, FileContent>;
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/validator.rs ‚àá‚àá‚àá
// src/apply/validator.rs
use crate::apply::messages;
use crate::apply::types::{ApplyOutcome, ExtractedFiles, Manifest, Operation};
use regex::Regex;
use std::sync::LazyLock;

const SENSITIVE_PATHS: &[&str] = &[
    ".git/",
    ".env",
    ".ssh/",
    ".aws/",
    ".gnupg/",
    "id_rsa",
    "id_ed25519",
    "credentials",
    ".warden_apply_backup/",
];

/// Compiled regex patterns for detecting lazy/truncated AI output.
/// These are compile-time constant patterns; if any fail to compile,
/// it's a programmer error that will surface immediately at first use.
static LAZY_MARKERS: LazyLock<Vec<Regex>> = LazyLock::new(|| {
    [
        // Matches "// ..."
        r"^\s*//\s*\.{3,}\s*$",
        // Matches "/* ... */"
        r"^\s*/\*\s*\.{3,}\s*\*/\s*$",
        // Matches phrases indicating omitted code.
        // warden:ignore
        r"(?i)^\s*//.*(rest of|remaining|existing|implement|logic here).*$",
        // Matches Python style "# ..."
        r"^\s*#\s*\.{3,}\s*$",
    ]
    .iter()
    .filter_map(|pattern| match Regex::new(pattern) {
        Ok(re) => Some(re),
        Err(e) => {
            eprintln!("Warning: Invalid lazy marker pattern '{pattern}': {e}");
            None
        }
    })
    .collect()
});

#[must_use]
pub fn validate(manifest: &Manifest, extracted: &ExtractedFiles) -> ApplyOutcome { ... }

fn check_path_safety(extracted: &ExtractedFiles, errors: &mut Vec<String>) { ... }

fn validate_single_path(path: &str, errors: &mut Vec<String>) { ... }

fn has_traversal(path: &str) -> bool { ... }

fn is_absolute_path(path: &str) -> bool { ... }

fn is_sensitive_path(path: &str) -> bool { ... }

fn is_hidden_file(path: &str) -> bool { ... }

fn check_missing(manifest: &Manifest, extracted: &ExtractedFiles) -> Vec<String> { ... }

fn check_content(extracted: &ExtractedFiles) -> Vec<String> { ... }

fn check_single_file(path: &str, content: &str, errors: &mut Vec<String>) { ... }

fn check_lazy_truncation(path: &str, content: &str, errors: &mut Vec<String>) { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/apply/writer.rs ‚àá‚àá‚àá
// src/apply/writer.rs
use crate::apply::types::{ApplyOutcome, ExtractedFiles, Manifest, Operation};
use anyhow::{anyhow, Context, Result};
use std::fs;
use std::path::{Path, PathBuf};
use std::time::{SystemTime, UNIX_EPOCH};

const BACKUP_DIR: &str = ".warden_apply_backup";

/// Writes changes (updates, new files, deletes) to disk.
///
/// # Errors
/// Returns error if file system operations fail.
pub fn write_files(
    manifest: &Manifest,
    files: &ExtractedFiles,
    root: Option<&Path>,
) -> Result<ApplyOutcome> { ... }

fn delete_file(path_str: &str, root: Option<&Path>) -> Result<()> { ... }

fn write_single_file(path_str: &str, content: &str, root: Option<&Path>) -> Result<()> { ... }

fn resolve_path(path_str: &str, root: Option<&Path>) -> PathBuf { ... }

fn create_backup(manifest: &Manifest, root: Option<&Path>) -> Result<Option<PathBuf>> { ... }

fn backup_single_file(path_str: &str, backup_folder: &Path, root: Option<&Path>) -> Result<()> { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/bin/warden.rs ‚àá‚àá‚àá
use anyhow::Result;
use clap::{Parser, Subcommand};
use colored::Colorize;
use std::fs;
use std::io;
use std::path::Path;
use std::process::{self, Command};

use warden_core::analysis::RuleEngine;
use warden_core::apply;
use warden_core::apply::types::ApplyContext;
use warden_core::config::Config;
use warden_core::discovery;
use warden_core::pack::{self, OutputFormat, PackOptions};
use warden_core::project;
use warden_core::prompt::PromptGenerator;
use warden_core::reporting;
use warden_core::roadmap::cli::{handle_command, RoadmapCommand};
use warden_core::tui::state::App;
use warden_core::types::ScanReport;

#[derive(Parser)]
#[command(name = "warden")]
#[command(version)]
#[command(about = "Code quality guardian", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Option<Commands>,
    #[arg(long)]
    ui: bool,
    #[arg(long)]
    init: bool,
}

#[derive(Subcommand)]
enum Commands {
    Prompt {
        #[arg(long, short)]
        copy: bool,
    },
    Check,
    Fix,
    Apply,
    #[command(subcommand)]
    Roadmap(RoadmapCommand),
    Pack {
        #[arg(long, short)]
        stdout: bool,
        #[arg(long, short)]
        copy: bool,
        /// Skip including the system prompt (prompt is included by default)
        #[arg(long)]
        noprompt: bool,
        #[arg(long, value_enum, default_value_t = OutputFormat::Text)]
        format: OutputFormat,
        #[arg(long)]
        skeleton: bool,
        #[arg(long)]
        git_only: bool,
        #[arg(long)]
        no_git: bool,
        #[arg(long)]
        code_only: bool,
        #[arg(long, short)]
        verbose: bool,
    },
}

fn main() { ... }

fn run() -> Result<()> { ... }

fn dispatch_command(cli: &Cli) -> Result<()> { ... }

fn dispatch_subcommand(cmd: &Commands) -> Result<()> { ... }

fn dispatch_default(ui: bool) -> Result<()> { ... }

fn handle_apply() -> Result<()> { ... }

fn ensure_config_exists() { ... }

fn init_config() -> Result<()> { ... }

fn handle_prompt(copy: bool) -> Result<()> { ... }

fn run_command(name: &str) -> Result<()> { ... }

fn exit_with_code(code: i32) -> Result<()> { ... }

fn handle_exec_error(e: &std::io::Error, prog: &str) { ... }

fn run_scan() -> Result<()> { ... }

fn run_tui() -> Result<()> { ... }

fn load_config() -> Config { ... }

fn scan_files(config: &Config, files: Vec<std::path::PathBuf>) -> ScanReport { ... }

fn run_tui_with_report(report: ScanReport) -> Result<()> { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/clipboard.rs ‚àá‚àá‚àá
#![allow(unused_imports)] // Context is used on some OS targets but not others

use anyhow::{Context, Result};
use std::fs;
use std::path::{Path, PathBuf};
use std::process::Command;
use std::time::{SystemTime, UNIX_EPOCH};
use crate::tokens::Tokenizer;

const TEMP_PREFIX: &str = "warden_clipboard_";

// --- Public API ---

/// Smartly copies text or file handles based on size.
///
/// # Errors
/// Returns error if clipboard access fails or temp file creation fails.
pub fn smart_copy(text: &str) -> Result<String> { ... }

/// Copies a file path to clipboard so it can be pasted as a file attachment.
///
/// # Errors
/// Returns error if clipboard access fails.
pub fn copy_file_path(path: &Path) -> Result<()> { ... }

/// Wrapper for backward compatibility. // warden:ignore
///
/// # Errors
/// Returns error if clipboard access fails.
pub fn copy_to_clipboard(text: &str) -> Result<()> { ... }

/// Reads text from the system clipboard.
///
/// # Errors
/// Returns error if clipboard access fails.
pub fn read_clipboard() -> Result<String> { ... }

// --- Internal Logic ---

fn write_to_temp(content: &str) -> Result<PathBuf> { ... }

fn cleanup_temp_files() { ... }

// Helper to reduce cyclomatic complexity of cleanup_temp_files
fn should_delete(path: &Path, now: SystemTime, limit: std::time::Duration) -> bool { ... }

// --- Platform Specifics (File Handles) ---

#[cfg(target_os = "windows")]
fn copy_file_handle(path: &Path) -> Result<()> { ... }

#[cfg(target_os = "macos")]
fn copy_file_handle(path: &Path) -> Result<()> { ... }

#[cfg(target_os = "linux")]
fn copy_file_handle(path: &Path) -> Result<()> { ... }

// --- Platform Specifics (Text Read/Write) ---

#[cfg(target_os = "macos")]
fn perform_copy(text: &str) -> Result<()> { ... }

#[cfg(target_os = "macos")]
fn perform_read() -> Result<String> { ... }

#[cfg(target_os = "linux")]
fn perform_copy(text: &str) -> Result<()> { ... }

#[cfg(target_os = "linux")]
fn perform_read() -> Result<String> { ... }

#[cfg(target_os = "windows")]
fn perform_copy(text: &str) -> Result<()> { ... }

#[cfg(target_os = "windows")]
fn perform_read() -> Result<String> { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/config.rs ‚àá‚àá‚àá
// src/config.rs
pub use crate::constants::{
    BIN_EXT_PATTERN, CODE_BARE_PATTERN, CODE_EXT_PATTERN, PRUNE_DIRS, SECRET_PATTERN,
};
use crate::error::Result;
use crate::project::{self, ProjectType};
use regex::Regex;
use serde::Deserialize;
use std::collections::HashMap;
use std::fs;
use std::path::Path;

#[derive(Debug, Clone, Deserialize)]
pub struct RuleConfig {
    #[serde(default = "default_max_tokens")]
    pub max_file_tokens: usize,
    #[serde(default = "default_max_complexity")]
    pub max_cyclomatic_complexity: usize,
    #[serde(default = "default_max_depth")]
    pub max_nesting_depth: usize,
    #[serde(default = "default_max_args")]
    pub max_function_args: usize,
    #[serde(default = "default_max_words")]
    pub max_function_words: usize,
    #[serde(default)]
    pub ignore_naming_on: Vec<String>,
    #[serde(default = "default_ignore_tokens")]
    pub ignore_tokens_on: Vec<String>,
}

impl Default for RuleConfig {
    fn default() -> Self { ... }
}

const fn default_max_tokens() -> usize { ... }
const fn default_max_complexity() -> usize { ... }
const fn default_max_depth() -> usize { ... }
const fn default_max_args() -> usize { ... }
const fn default_max_words() -> usize { ... }
fn default_ignore_tokens() -> Vec<String> { ... }

#[derive(Debug, Clone, Deserialize, Default)]
pub struct WardenToml {
    #[serde(default)]
    pub rules: RuleConfig,
    #[serde(default)]
    pub commands: HashMap<String, String>,
}

#[derive(Debug, Clone)]
pub enum GitMode {
    Auto,
    Yes,
    No,
}

#[derive(Debug, Clone)]
pub struct Config {
    pub git_mode: GitMode,
    pub include_patterns: Vec<Regex>,
    pub exclude_patterns: Vec<Regex>,
    pub code_only: bool,
    pub verbose: bool,
    pub rules: RuleConfig,
    pub commands: HashMap<String, String>,
}

impl Default for Config {
    fn default() -> Self { ... }
}

impl Config {
    #[must_use]
    pub fn new() -> Self { ... }

    /// Validates configuration.
    /// # Errors
    /// Currently always returns Ok.
    pub fn validate(&self) -> Result<()> { ... }

    pub fn load_local_config(&mut self) { ... }

    fn apply_project_defaults(&mut self) { ... }

    fn load_ignore_file(&mut self) { ... }

    fn process_ignore_line(&mut self, line: &str) { ... }

    fn load_toml_config(&mut self) { ... }

    fn parse_toml(&mut self, content: &str) { ... }
}

fn project_defaults(project: ProjectType) -> HashMap<String, String> { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/constants.rs ‚àá‚àá‚àá
// src/constants.rs
//! Shared constants for file filtering and pattern matching.

pub const PRUNE_DIRS: &[&str] = &[
    ".git",
    ".svn",
    ".hg",
    "node_modules",
    "target",
    "dist",
    "build",
    "out",
    "gen",
    ".venv",
    "venv",
    ".tox",
    "__pycache__",
    "coverage",
    "vendor",
    ".warden_apply_backup",
];

pub const PRUNE_FILES: &[&str] = &[
    "Cargo.lock",
    "package-lock.json",
    "pnpm-lock.yaml",
    "yarn.lock",
    "bun.lockb",
    "go.sum",
    "Gemfile.lock",
];

pub const SKIP_DIRS: &[&str] = &["tests", "test", "spec", "docs", "examples", "fixtures"];

pub const BIN_EXT_PATTERN: &str =
    r"(?i)\.(png|jpg|gif|svg|ico|webp|woff2?|ttf|pdf|mp4|zip|gz|tar|exe|dll|so|dylib|class|pyc)$";

pub const SECRET_PATTERN: &str =
    r"(?i)(^\.?env(\..*)?$|/\.?env(\..*)?$|(^|/)(id_rsa|id_ed25519|.*\.(pem|p12|key|pfx))$)";

pub const CODE_EXT_PATTERN: &str = r"(?i)\.(rs|go|py|js|jsx|ts|tsx|java|c|cpp|h|hpp|cs|php|rb|sh|sql|html|css|scss|json|toml|yaml|md)$";

pub const CODE_BARE_PATTERN: &str = r"(?i)(Makefile|Dockerfile|CMakeLists\.txt)$";

/// Checks if a directory name should be pruned during traversal.
#[must_use]
pub fn should_prune(name: &str) -> bool { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/detection.rs ‚àá‚àá‚àá
// src/detection.rs
use crate::error::Result;
use std::collections::HashSet;
use std::fmt;
use std::path::Path;

#[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
pub enum BuildSystemType {
    Rust,
    Node,
    Python,
    Go,
    CMake,
    Conan,
}

impl fmt::Display for BuildSystemType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result { ... }
}

#[derive(Default)]
pub struct Detector;

impl Detector {
    #[must_use]
    pub fn new() -> Self { ... }

    /// Detects build systems.
    /// # Errors
    /// Returns `Ok`.
    pub fn detect_build_systems(
        &self,
        files: &[std::path::PathBuf],
    ) -> Result<Vec<BuildSystemType>> { ... }
}

fn check_file(path: &Path, set: &mut HashSet<BuildSystemType>) { ... }

fn check_cmake(path: &Path, set: &mut HashSet<BuildSystemType>) -> bool { ... }

const COMMON_CONFIGS: &[(&str, BuildSystemType)] = &[
    ("Cargo.toml", BuildSystemType::Rust),
    ("package.json", BuildSystemType::Node),
    ("requirements.txt", BuildSystemType::Python),
    ("pyproject.toml", BuildSystemType::Python),
    ("Pipfile", BuildSystemType::Python),
    ("go.mod", BuildSystemType::Go),
    ("CMakeLists.txt", BuildSystemType::CMake),
    ("conanfile.txt", BuildSystemType::Conan),
    ("conanfile.py", BuildSystemType::Conan),
];

fn check_common(name: &str, set: &mut HashSet<BuildSystemType>) { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/discovery.rs ‚àá‚àá‚àá
// src/discovery.rs
use crate::config::{
    Config, GitMode, BIN_EXT_PATTERN, CODE_BARE_PATTERN, CODE_EXT_PATTERN, SECRET_PATTERN,
};
use crate::constants::should_prune;
use crate::error::{Result, WardenError};
use regex::Regex;
use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};
use std::process::Command;
use std::sync::LazyLock;
use walkdir::WalkDir;

/// Runs the full file discovery pipeline: Enumerate -> Heuristics -> Filter.
///
/// # Errors
/// Returns error if git commands fail or regexes are invalid.
pub fn discover(config: &Config) -> Result<Vec<PathBuf>> { ... }

// --- Enumeration ---

fn enumerate_files(config: &Config) -> Result<Vec<PathBuf>> { ... }

fn enumerate_git_required() -> Result<Vec<PathBuf>> { ... }

fn enumerate_auto(verbose: bool) -> Vec<PathBuf> { ... }

fn walk_filesystem(verbose: bool) -> Vec<PathBuf> { ... }

fn accumulate_walker<I>(walker: I) -> (Vec<PathBuf>, usize)
where
    I: Iterator<Item = walkdir::Result<walkdir::DirEntry>>,
{ ... }

fn in_git_repo() -> bool { ... }

fn git_ls_files() -> Result<Vec<PathBuf>> { ... }

fn filter_pruned(paths: Vec<PathBuf>) -> Vec<PathBuf> { ... }

fn contains_pruned_component(path: &Path) -> bool { ... }

// --- Heuristics ---

const MIN_TEXT_ENTROPY: f64 = 3.5;
const MAX_TEXT_ENTROPY: f64 = 5.5;
const BUILD_MARKERS: &[&str] = &[
    "find_package",
    "add_executable",
    "target_link_libraries",
    "cmake_minimum_required",
    "project(",
    "add-apt-repository",
    "conanfile.py",
    "dependency",
    "require",
    "include",
    "import",
];

static CODE_EXT_RE: LazyLock<Option<Regex>> = LazyLock::new(|| Regex::new(CODE_EXT_PATTERN).ok());
static CODE_BARE_RE: LazyLock<Option<Regex>> = LazyLock::new(|| Regex::new(CODE_BARE_PATTERN).ok());

fn filter_heuristics(files: Vec<PathBuf>) -> Vec<PathBuf> { ... }

fn keep_heuristic(path: &Path) -> bool { ... }

fn is_known_code(path_str: &str) -> bool { ... }

fn has_build_markers(path: &Path) -> bool { ... }

#[allow(clippy::cast_precision_loss)]
fn calculate_entropy(path: &Path) -> std::io::Result<f64> { ... }

// --- Config Filter ---

struct FilterContext<'a> {
    config: &'a Config,
    bin_re: Regex,
    secret_re: Regex,
    code_re: Option<Regex>,
    bare_re: Option<Regex>,
}

fn filter_config(files: Vec<PathBuf>, config: &Config) -> Result<Vec<PathBuf>> { ... }

fn should_keep_config(path: &Path, ctx: &FilterContext) -> bool { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/error.rs ‚àá‚àá‚àá
// src/error.rs
use std::path::PathBuf;
use thiserror::Error;

#[derive(Debug, Error)]
pub enum WardenError {
    #[error("I/O error: {source} (path: {path})")]
    Io {
        source: std::io::Error,
        path: PathBuf,
    },

    #[error("Not inside a Git repository")]
    NotInGitRepo,

    #[error("Regex error: {0}")]
    Regex(#[from] regex::Error),

    #[error("Generic error: {0}")]
    Other(String),
}

pub type Result<T> = std::result::Result<T, WardenError>;

// Allow `?` on std::io::Error by converting to WardenError::Io with unknown path.
impl From<std::io::Error> for WardenError {
    fn from(source: std::io::Error) -> Self { ... }
}

// Gracefully convert WalkDir errors
impl From<walkdir::Error> for WardenError {
    fn from(e: walkdir::Error) -> Self { ... }
}

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/lib.rs ‚àá‚àá‚àá
// src/lib.rs
pub mod analysis;
pub mod apply;
pub mod clipboard;
pub mod config;
pub mod constants;
pub mod discovery;
pub mod error;
pub mod pack;
pub mod project;
pub mod prompt;
pub mod reporting;
pub mod roadmap;
pub mod skeleton;
pub mod tokens;
pub mod tui;
pub mod types;

// Legacy/Test compatibility aliases
pub use analysis as rules;
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/pack.rs ‚àá‚àá‚àá
// src/pack.rs
use crate::analysis::RuleEngine;
use crate::clipboard;
use crate::config::{Config, GitMode};
use crate::discovery;
use crate::prompt::PromptGenerator;
use crate::skeleton;
use crate::tokens::Tokenizer;
use anyhow::Result;
use clap::ValueEnum;
use colored::Colorize;
use std::fmt::Write;
use std::fs;
use std::path::PathBuf;

#[derive(Debug, Clone, ValueEnum, Default)]
pub enum OutputFormat {
    #[default]
    Text,
    Xml,
}

#[allow(clippy::struct_excessive_bools)]
#[derive(Default)]
pub struct PackOptions {
    pub stdout: bool,
    pub copy: bool,
    pub verbose: bool,
    pub prompt: bool,
    pub format: OutputFormat,
    pub skeleton: bool,
    pub git_only: bool,
    pub no_git: bool,
    pub code_only: bool,
}

/// Entry point for the pack command.
///
/// # Errors
/// Returns error if:
/// - Configuration loading fails
/// - File discovery fails
/// - Content generation fails
/// - Clipboard access fails (if --copy is used)
/// - File writing fails
pub fn run(options: &PackOptions) -> Result<()> { ... }

fn setup_config(opts: &PackOptions) -> Result<Config> { ... }

/// Generates the context content string from a list of files.
/// Exposed for testing purposes.
///
/// # Errors
/// Returns error if file reading fails.
pub fn generate_content(files: &[PathBuf], opts: &PackOptions, config: &Config) -> Result<String> { ... }

fn inject_violations(ctx: &mut String, files: &[PathBuf], config: &Config) -> Result<()> { ... }

fn write_body(files: &[PathBuf], ctx: &mut String, opts: &PackOptions) -> Result<()> { ... }

fn write_header(ctx: &mut String, config: &Config) -> Result<()> { ... }

fn write_footer(ctx: &mut String, config: &Config) -> Result<()> { ... }

fn output_result(content: &str, tokens: usize, opts: &PackOptions) -> Result<()> { ... }

fn pack_nabla(files: &[PathBuf], out: &mut String, skeleton: bool) -> Result<()> { ... }

fn pack_xml(files: &[PathBuf], out: &mut String, skeleton: bool) -> Result<()> { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/project.rs ‚àá‚àá‚àá
// src/project.rs
use std::path::Path;

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum ProjectType {
    Rust,
    Node,
    Python,
    Go,
    Unknown,
}

impl ProjectType {
    #[must_use]
    pub fn detect() -> Self { ... }

    /// Detects if this is a TypeScript project
    #[must_use]
    pub fn is_typescript() -> bool { ... }
}

fn has_ts_files() -> bool { ... }

#[must_use]
pub fn generate_toml() -> String { ... }

fn rules_section() -> String { ... }

fn commands_section(project: ProjectType) -> String { ... }

fn rust_commands() -> String { ... }

fn node_commands() -> String { ... }

fn python_commands() -> String { ... }

fn go_commands() -> String { ... }

fn unknown_commands() -> String { ... }

#[must_use]
pub fn npx_cmd() -> &'static str { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/prompt.rs ‚àá‚àá‚àá
// src/prompt.rs
use crate::config::RuleConfig;
use anyhow::Result;

pub struct PromptGenerator {
    config: RuleConfig,
}

impl PromptGenerator {
    #[must_use]
    pub fn new(config: RuleConfig) -> Self { ... }

    /// Generates the full system prompt.
    /// # Errors
    /// Currently infallible, returns Result for API consistency.
    pub fn generate(&self) -> Result<String> { ... }

    /// Generates a short reminder prompt for context footers.
    /// # Errors
    /// Currently infallible, returns Result for API consistency.
    pub fn generate_reminder(&self) -> Result<String> { ... }

    /// Alias for `generate()` ‚Äî used by knit for context headers.
    /// # Errors
    /// Currently infallible, returns Result for API consistency.
    pub fn wrap_header(&self) -> Result<String> { ... }

    fn build_system_prompt(&self) -> String { ... }

    fn build_reminder(&self) -> String { ... }
}

fn build_output_format() -> String { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/reporting.rs ‚àá‚àá‚àá
// src/reporting.rs
use crate::types::{FileReport, ScanReport, Violation};
use anyhow::Result;
use colored::Colorize;

/// Prints the scan report to stdout.
///
/// # Errors
/// Returns `Ok(())` normally.
pub fn print_report(report: &ScanReport) -> Result<()> { ... }

fn count_failures(report: &ScanReport) -> usize { ... }

fn print_file_report(file: &FileReport) { ... }

fn print_violation(path: &std::path::Path, v: &Violation) { ... }

fn print_summary(report: &ScanReport, failures: usize) { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/cli.rs ‚àá‚àá‚àá
use crate::clipboard;
use crate::roadmap::{
    apply_commands, generate_prompt, CommandBatch, PromptOptions, Roadmap, TaskStatus,
};
use anyhow::{anyhow, Context, Result};
use clap::Subcommand;
use std::io::{self, Read};
use std::path::{Path, PathBuf};

#[derive(Subcommand, Debug, Clone)]
pub enum RoadmapCommand {
    Init {
        #[arg(short, long, default_value = "ROADMAP.md")]
        output: PathBuf,
        #[arg(short, long)]
        name: Option<String>,
    },
    Prompt {
        #[arg(short, long, default_value = "ROADMAP.md")]
        file: PathBuf,
        #[arg(long)]
        full: bool,
        #[arg(long)]
        examples: bool,
        #[arg(long)]
        stdout: bool,
    },
    Apply {
        #[arg(short, long, default_value = "ROADMAP.md")]
        file: PathBuf,
        #[arg(long)]
        dry_run: bool,
        #[arg(long)]
        stdin: bool,
        #[arg(short, long)]
        verbose: bool,
    },
    Show {
        #[arg(short, long, default_value = "ROADMAP.md")]
        file: PathBuf,
        #[arg(long, default_value = "tree")]
        format: String,
    },
    Tasks {
        #[arg(short, long, default_value = "ROADMAP.md")]
        file: PathBuf,
        #[arg(long)]
        pending: bool,
        #[arg(long)]
        complete: bool,
    },
}

/// Entry point for roadmap commands
/// # Errors
/// Returns error if IO fails or clipboard access fails
pub fn handle_command(cmd: RoadmapCommand) -> Result<()> { ... }

fn run_init(output: &Path, name: Option<String>) -> Result<()> { ... }

fn run_prompt(file: &Path, full: bool, examples: bool, stdout: bool) -> Result<()> { ... }

fn run_apply(file: &Path, dry_run: bool, stdin: bool, verbose: bool) -> Result<()> { ... }

fn run_show(file: &Path, format: &str) -> Result<()> { ... }

fn run_tasks(file: &Path, pending: bool, complete: bool) -> Result<()> { ... }

fn should_show_task(status: TaskStatus, pending: bool, complete: bool) -> bool { ... }

fn load(path: &Path) -> Result<Roadmap> { ... }

fn get_input(stdin: bool) -> Result<String> { ... }

fn print_errs(errors: &[String]) { ... }

fn template(name: &str) -> String { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/cmd_parser.rs ‚àá‚àá‚àá
// src/roadmap/cmd_parser.rs
use crate::roadmap::types::{Command, CommandBatch, MovePosition};

impl CommandBatch {
    #[must_use]
    pub fn parse(input: &str) -> Self { ... }

    #[must_use]
    pub fn summary(&self) -> String { ... }
}

// Split match to reduce Cyclomatic Complexity (Max 8)
fn cmd_name(cmd: &Command) -> &'static str { ... }

fn cmd_name_extended(cmd: &Command) -> &'static str { ... }

fn extract_roadmap_block(input: &str) -> &str { ... }

fn is_skippable(line: &str) -> bool { ... }

fn parse_command_line(line: &str) -> Result<Command, String> { ... }

fn is_basic(cmd: &str) -> bool { ... }
fn is_content(cmd: &str) -> bool { ... }
fn is_struct(cmd: &str) -> bool { ... }

fn parse_basic(cmd: &str, args: &str) -> Result<Command, String> { ... }

fn parse_content(cmd: &str, args: &str) -> Result<Command, String> { ... }

fn parse_struct(cmd: &str, args: &str) -> Result<Command, String> { ... }

fn split_cmd(line: &str) -> Option<(&str, &str)> { ... }

fn req_path(args: &str) -> Result<String, String> { ... }

fn parse_add(args: &str) -> Result<Command, String> { ... }

fn parse_update(args: &str) -> Result<Command, String> { ... }

fn parse_note(args: &str) -> Result<Command, String> { ... }

fn parse_move(args: &str) -> Result<Command, String> { ... }

fn parse_section(args: &str) -> Result<Command, String> { ... }

fn split_first_word(s: &str) -> (&str, &str) { ... }

fn parse_quoted(s: &str) -> Result<String, String> { ... }

fn parse_quoted_with_after(s: &str) -> Result<(String, Option<String>), String> { ... }

fn extract_quoted_text(s: &str) -> Result<(String, &str), String> { ... }

fn is_ignorable(line: &str) -> bool { ... }

fn truncate(s: &str, max: usize) -> String { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/cmd_runner.rs ‚àá‚àá‚àá
use crate::roadmap::parser::slugify;
use crate::roadmap::types::{
    ApplyResult, Command, CommandBatch, MovePosition, Roadmap, TaskStatus,
};

pub fn apply_commands(roadmap: &mut Roadmap, batch: &CommandBatch) -> Vec<ApplyResult> { ... }

fn run_cmd(roadmap: &mut Roadmap, cmd: &Command) -> ApplyResult { ... }

fn set_status(roadmap: &mut Roadmap, path: &str, status: TaskStatus) -> ApplyResult { ... }

fn run_add(roadmap: &mut Roadmap, parent: &str, text: &str, after: Option<&str>) -> ApplyResult { ... }

fn run_delete(roadmap: &mut Roadmap, path: &str) -> ApplyResult { ... }

fn run_update(roadmap: &mut Roadmap, path: &str, text: &str) -> ApplyResult { ... }

fn run_note(roadmap: &mut Roadmap, path: &str, note: &str) -> ApplyResult { ... }

#[allow(dead_code)]
fn apply_move(_: &mut Roadmap, path: &str, _: &MovePosition) -> ApplyResult { ... }

#[allow(dead_code)]
fn apply_section_replace(_: &mut Roadmap, id: &str, _: &str) -> ApplyResult { ... }

// --- Logic Helpers ---

// Refactored to reduce nesting depth
fn scan_insertion_point(lines: &[&str], parent: &str, after: Option<&str>) -> Option<usize> { ... }

#[derive(Default)]
struct ScanState {
    in_sec: bool,
    last_task: Option<usize>,
    sec_start: Option<usize>,
    found_index: Option<usize>,
}

fn process_line(line: &str, i: usize, p_slug: &str, after: Option<&str>, state: &mut ScanState) { ... }

fn check_section_entry(line: &str, parent_slug: &str) -> bool { ... }

fn check_after_match(line: &str, after: Option<&str>) -> bool { ... }

fn find_line_idx(roadmap: &Roadmap, path: &str) -> Option<usize> { ... }

fn update_line_status(roadmap: &mut Roadmap, idx: usize, status: TaskStatus) -> bool { ... }

// --- Mutation Helpers ---

fn replace_raw(roadmap: &mut Roadmap, idx: usize, line: String) { ... }

fn insert_raw(roadmap: &mut Roadmap, idx: usize, line: String) { ... }

fn remove_raw(roadmap: &mut Roadmap, idx: usize) { ... }

fn modify_lines<F>(roadmap: &mut Roadmap, f: F)
where
    F: FnOnce(&mut Vec<String>),
{ ... }

fn is_task(line: &str) -> bool { ... }

fn ok_res(status: TaskStatus, path: &str) -> ApplyResult { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/display.rs ‚àá‚àá‚àá
use crate::roadmap::types::{Roadmap, Section, TaskStatus};
use std::fmt::Write;

impl Roadmap {
    /// Generate a compact state representation for AI context
    #[must_use]
    pub fn compact_state(&self) -> String { ... }
}

fn format_section_compact(section: &Section, depth: usize) -> String { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/mod.rs ‚àá‚àá‚àá
pub mod cli;
pub mod cmd_parser;
pub mod cmd_runner;
pub mod display;
pub mod parser;
pub mod prompt;
pub mod types;

// Re-export CommandBatch from types, not cmd_parser
pub use cmd_runner::apply_commands;
pub use parser::slugify;
pub use prompt::{generate_prompt, PromptOptions};
pub use types::CommandBatch;
pub use types::*;

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/parser.rs ‚àá‚àá‚àá
use crate::roadmap::types::{Roadmap, RoadmapStats, Section, Task, TaskStatus};
use std::path::Path;

impl Roadmap {
    /// Parse a roadmap from markdown content
    #[must_use]
    pub fn parse(content: &str) -> Self { ... }

    /// Parse from a file
    /// # Errors
    /// Returns error on file read fail
    pub fn from_file(path: &Path) -> std::io::Result<Self> { ... }

    /// Save back to file
    /// # Errors
    /// Returns error on file write fail
    pub fn save(&self, path: &Path) -> std::io::Result<()> { ... }

    #[must_use]
    pub fn all_tasks(&self) -> Vec<&Task> { ... }

    #[must_use]
    pub fn find_task(&self, path: &str) -> Option<&Task> { ... }

    #[must_use]
    pub fn stats(&self) -> RoadmapStats { ... }
}

// --- Parsing helpers ---

fn parse_heading(line: &str) -> Option<(u8, String)> { ... }

fn parse_section(lines: &[&str], i: &mut usize, lvl: u8, heading: String) -> Section { ... }

fn parse_task(line: &str, line_num: usize) -> Option<Task> { ... }

fn collect_tasks<'a>(s: &'a Section, out: &mut Vec<&'a Task>) { ... }

/// Convert text to a URL-safe slug
#[must_use]
pub fn slugify(text: &str) -> String { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/prompt.rs ‚àá‚àá‚àá
use crate::roadmap::types::{Roadmap, Section, TaskStatus};
use std::fmt::Write;

/// Options for prompt generation
#[derive(Debug, Clone, Default)]
pub struct PromptOptions {
    pub full: bool,
    pub examples: bool,
    pub project_name: Option<String>,
}

/// Generate the teaching prompt for AI
#[must_use]
pub fn generate_prompt(roadmap: &Roadmap, options: &PromptOptions) -> String { ... }

fn generate_compact_state(roadmap: &Roadmap) -> String { ... }

fn format_section_tree(section: &Section, depth: usize) -> String { ... }

fn count_tasks_recursive(section: &Section) -> (usize, usize) { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/roadmap/types.rs ‚àá‚àá‚àá
use std::fmt;

#[derive(Debug, Clone)]
pub struct Roadmap {
    pub path: Option<String>,
    pub title: String,
    pub sections: Vec<Section>,
    pub raw: String,
}

#[derive(Debug, Clone)]
pub struct Section {
    pub id: String,
    pub heading: String,
    pub level: u8,
    pub theme: Option<String>,
    pub tasks: Vec<Task>,
    pub subsections: Vec<Section>,
    pub raw_content: String,
    pub line_start: usize,
    pub line_end: usize,
}

#[derive(Debug, Clone)]
pub struct Task {
    pub id: String,
    pub path: String,
    pub text: String,
    pub status: TaskStatus,
    pub indent: u8,
    pub line: usize,
    pub children: Vec<Task>,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TaskStatus {
    Pending,
    Complete,
}

#[derive(Debug, Clone)]
pub struct RoadmapStats {
    pub total: usize,
    pub complete: usize,
    pub pending: usize,
}

/// A single command from AI
#[derive(Debug, Clone)]
pub enum Command {
    Check {
        path: String,
    },
    Uncheck {
        path: String,
    },
    Add {
        parent: String,
        text: String,
        after: Option<String>,
    },
    Delete {
        path: String,
    },
    Update {
        path: String,
        text: String,
    },
    Note {
        path: String,
        note: String,
    },
    Move {
        path: String,
        position: MovePosition,
    },
    ReplaceSection {
        id: String,
        content: String,
    },
}

#[derive(Debug, Clone)]
pub enum MovePosition {
    After(String),
    Before(String),
}

/// A batch of commands parsed from AI output
#[derive(Debug, Clone)]
pub struct CommandBatch {
    pub commands: Vec<Command>,
    pub errors: Vec<String>,
}

/// Result of applying a command
#[derive(Debug)]
pub enum ApplyResult {
    Success(String),
    NotFound(String),
    Error(String),
}

impl fmt::Display for ApplyResult {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result { ... }
}

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/skeleton.rs ‚àá‚àá‚àá
// src/skeleton.rs
use std::path::Path;
use std::sync::LazyLock;
use tree_sitter::{Language, Parser, Query, QueryCursor};

static SKELETONIZER: LazyLock<Skeletonizer> = LazyLock::new(Skeletonizer::new);

struct Skeletonizer {
    rust: Query,
    python: Query,
    javascript: Query,
}

impl Skeletonizer {
    fn new() -> Self { ... }

    fn get_config<'a>(&'a self, lang: &str) -> Option<(Language, &'a Query, &'static str)> { ... }
}

/// Reduces code to its structural skeleton (signatures only).
///
/// # Arguments
/// * `path` - The file path (used for language detection).
/// * `content` - The full source code.
///
/// # Returns
/// The skeletonized code, or the original content if language is unsupported.
#[must_use]
pub fn clean(path: &Path, content: &str) -> String { ... }

fn apply_skeleton(source: &str, lang: Language, query: &Query, replacement: &str) -> String { ... }

fn filter_nested_ranges(mut ranges: Vec<std::ops::Range<usize>>) -> Vec<std::ops::Range<usize>> { ... }

fn replace_ranges(source: &str, ranges: &[std::ops::Range<usize>], replacement: &str) -> String { ... }

fn compile_query(lang: Language, pattern: &str) -> Query { ... }
‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/tokens.rs ‚àá‚àá‚àá
// src/tokens.rs
use std::sync::LazyLock;
use tiktoken_rs::CoreBPE;

/// The tokenizer encoding (`cl100k_base`, used by GPT-4/3.5-turbo).
/// Initialization is deferred until first use. If the encoding fails to load
/// (which should never happen with a valid tiktoken-rs installation),
/// token counting will return 0 and log an error.
static BPE: LazyLock<Option<CoreBPE>> = LazyLock::new(|| {
    tiktoken_rs::cl100k_base()
        .map_err(|e| eprintln!("Failed to load cl100k_base tokenizer: {e}"))
        .ok()
});

pub struct Tokenizer;

impl Tokenizer {
    /// Counts the number of tokens in the given text.
    /// Returns 0 if the tokenizer failed to initialize.
    #[must_use]
    pub fn count(text: &str) -> usize { ... }

    /// Returns true if the text exceeds the token limit.
    #[must_use]
    pub fn exceeds_limit(text: &str, limit: usize) -> bool { ... }

    /// Returns true if the tokenizer is available.
    #[must_use]
    pub fn is_available() -> bool { ... }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tokenizer_available() { ... }

    #[test]
    fn test_count_basic() { ... }

    #[test]
    fn test_exceeds_limit() { ... }
}

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/tui/mod.rs ‚àá‚àá‚àá
pub mod state;
pub mod view;

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/tui/state.rs ‚àá‚àá‚àá
// src/tui/state.rs
use crate::types::{FileReport, ScanReport};
use anyhow::Result;
use crossterm::event::{self, Event, KeyCode};
use std::time::Duration;

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum SortMode {
    Path,
    Tokens,
    Violations,
}

pub struct App {
    pub report: ScanReport,
    pub view_indices: Vec<usize>,
    pub selected_index: usize,
    pub running: bool,
    pub sort_mode: SortMode,
    pub only_violations: bool,
}

impl App {
    #[must_use]
    pub fn new(report: ScanReport) -> Self { ... }

    fn update_view(&mut self) { ... }

    fn sort_indices(&self, indices: &mut [usize]) { ... }

    fn clamp_selection(&mut self) { ... }

    /// Runs TUI loop.
    /// # Errors
    /// Returns error on IO failure.
    pub fn run<B: ratatui::backend::Backend>(
        &mut self,
        terminal: &mut ratatui::Terminal<B>,
    ) -> Result<()> { ... }

    fn process_event(&mut self) -> Result<()> { ... }

    fn handle_input(&mut self, code: KeyCode) { ... }

    fn handle_nav(&mut self, code: KeyCode) -> bool { ... }

    fn handle_quit(&mut self, code: KeyCode) -> bool { ... }

    fn handle_toggles(&mut self, code: KeyCode) { ... }

    fn move_up(&mut self) { ... }

    fn move_down(&mut self) { ... }

    fn cycle_sort(&mut self) { ... }

    fn toggle_filter(&mut self) { ... }

    #[must_use]
    pub fn get_selected_file(&self) -> Option<&FileReport> { ... }
}

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/tui/view/components.rs ‚àá‚àá‚àá
// src/tui/view/components.rs
use crate::tui::state::App;
use crate::types::FileReport;
use ratatui::layout::{Alignment, Constraint, Direction, Layout, Rect};
use ratatui::style::{Color, Modifier, Style};
use ratatui::text::{Line, Span};
use ratatui::widgets::{Block, Borders, Gauge, List, ListItem, Paragraph};
use ratatui::Frame;

pub fn draw_file_list(f: &mut Frame, app: &App, area: Rect) { ... }

fn build_list_items(app: &App) -> Vec<ListItem<'_>> { ... }

fn create_list_item(file: &FileReport) -> ListItem<'_> { ... }

#[allow(clippy::cast_precision_loss)]
pub fn draw_inspector(f: &mut Frame, app: &App, area: Rect) { ... }

fn draw_header(f: &mut Frame, file: &FileReport, area: Rect) { ... }

#[allow(clippy::cast_precision_loss)]
fn draw_stats(f: &mut Frame, file: &FileReport, area: Rect) { ... }

fn draw_issues(f: &mut Frame, file: &FileReport, area: Rect) { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/tui/view/layout.rs ‚àá‚àá‚àá
// src/tui/view/layout.rs
use crate::tui::state::{App, SortMode};
use crate::tui::view::components;
use ratatui::layout::{Alignment, Constraint, Direction, Layout, Rect};
use ratatui::style::{Color, Modifier, Style};
use ratatui::text::{Line, Span};
use ratatui::widgets::{Block, Borders, Paragraph};
use ratatui::Frame;

pub fn render_dashboard(f: &mut Frame, app: &App, area: Rect) { ... }

#[allow(clippy::cast_precision_loss)]
fn draw_header(f: &mut Frame, app: &App, area: Rect) { ... }

fn count_stats(app: &App) -> (usize, usize) { ... }

fn get_health_color(health: f64) -> Color { ... }

fn build_info_string(app: &App, total: usize) -> String { ... }

fn get_sort_label(mode: SortMode) -> &'static str { ... }

fn get_filter_label(active: bool) -> &'static str { ... }

fn build_header_line(health: f64, info: &str) -> Line<'_> { ... }

fn draw_main(f: &mut Frame, app: &App, area: Rect) { ... }

fn get_main_chunks(area: Rect) -> std::rc::Rc<[Rect]> { ... }

fn draw_footer(f: &mut Frame, area: Rect) { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/tui/view/mod.rs ‚àá‚àá‚àá
// src/tui/view/mod.rs
pub mod components;
pub mod layout;

use crate::tui::state::App;
use ratatui::Frame;

pub fn draw(f: &mut Frame, app: &App) { ... }

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá src/types.rs ‚àá‚àá‚àá
// src/types.rs
use std::path::PathBuf;

/// A single violation detected during analysis.
#[derive(Debug, Clone)]
pub struct Violation {
    pub row: usize,
    pub message: String,
    pub law: &'static str,
}

/// Analysis results for a single file.
#[derive(Debug, Clone)]
pub struct FileReport {
    pub path: PathBuf,
    pub token_count: usize,
    pub complexity_score: usize,
    pub violations: Vec<Violation>,
}

impl FileReport {
    /// Returns true if no violations were found.
    #[must_use]
    pub fn is_clean(&self) -> bool { ... }

    /// Returns the number of violations.
    #[must_use]
    pub fn violation_count(&self) -> usize { ... }
}

/// Aggregated results from scanning multiple files.
#[derive(Debug, Clone, Default)]
pub struct ScanReport {
    pub files: Vec<FileReport>,
    pub total_tokens: usize,
    pub total_violations: usize,
    pub duration_ms: u128,
}

impl ScanReport {
    /// Returns true if any violations were found.
    #[must_use]
    pub fn has_errors(&self) -> bool { ... }

    /// Returns the number of clean files.
    #[must_use]
    pub fn clean_file_count(&self) -> usize { ... }
}

‚àÜ‚àÜ‚àÜ

‚àá‚àá‚àá warden.toml ‚àá‚àá‚àá
# warden.toml
[rules]
max_file_tokens = 2000
max_cyclomatic_complexity = 8
max_nesting_depth = 3
max_function_args = 5
max_function_words = 5
ignore_naming_on = ["tests", "spec"]

[commands]
check = "cargo clippy --all-targets -- -D warnings -D clippy::pedantic"
fix = "cargo fmt"

‚àÜ‚àÜ‚àÜ


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
END CODEBASE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

WARDEN CONSTRAINTS:
‚ñ° Files < 2000 tokens
‚ñ° Complexity ‚â§ 8
‚ñ° Nesting ‚â§ 3
‚ñ° Args ‚â§ 5
‚ñ° No .unwrap() or .expect()
‚ñ° Use Nabla Format (‚àá‚àá‚àá ... ‚àÜ‚àÜ‚àÜ)
